{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8SuX/pC+v43UolAwybz5z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayesha-Imr/Graph-RAG-Automation-ApertureDB-Gemini/blob/main/Notebooks/GraphRAG_with_ApertureDB_Part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GraphRAG with ApertureDB: Part 2 - Implementing and Evaluating Graph RAG\n",
        "\n",
        "Welcome to the second part of our tutorial! In [Part 1](https://colab.research.google.com/drive/1AckPhZUWFC22MNyZgWE5Zb5q9WEKRSgx?usp=drive_open#scrollTo=X0pWcgojnygK), we successfully built a knowledge graph from a PDF document and ingested it into ApertureDB. Now, we'll put that graph to work.\n",
        "\n",
        "Our goal is to build a Q&A system using two different Retrieval-Augmented Generation (RAG) methods and compare their performance.\n",
        "\n",
        "1.  **Vanilla RAG:** A standard approach using pure vector search to find relevant information.\n",
        "2.  **Graph RAG:** A more advanced method that leverages the connections within our knowledge graph to find richer, more contextual information."
      ],
      "metadata": {
        "id": "b2eepy1jarMf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Environment Setup\n",
        "\n",
        "First, let's install the necessary libraries and set up our clients for [ApertureDB](https://www.aperturedata.io/) and Google's [Gemini](https://ai.google.dev/gemini-api/docs/models) models. We'll be using Gemini for both embedding our queries and for generating the final answers."
      ],
      "metadata": {
        "id": "qum_R-GDa5K7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "n1zoQVYEI5qo",
        "outputId": "dd0e6ea8-61c9-435d-95fe-6454fcbe75f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.0/141.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.8/137.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for keepalive-socket (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q  aperturedb google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Core imports\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from typing import Dict, List, Any\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# Data models and utilities\n",
        "from pydantic import BaseModel, Field\n",
        "from google.colab import userdata, files\n",
        "from aperturedb.CommonLibrary import create_connector\n",
        "from IPython.display import HTML, display\n",
        "import pprint\n",
        "from google import genai\n",
        "from google.genai import types, errors"
      ],
      "metadata": {
        "id": "d6yVimXjJCnz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up the API keys. You can get a Google API key [here](https://aistudio.google.com/apikey)."
      ],
      "metadata": {
        "id": "o0YQcnL0bZez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db_host = userdata.get(\"APERTUREDB_HOST\")\n",
        "db_key = userdata.get(\"APERTUREDB_KEY\")\n",
        "google_api_key = userdata.get(\"GOOGLE_API_KEY\")"
      ],
      "metadata": {
        "id": "eLXTd1mXmcUm"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to the ApertureDB client."
      ],
      "metadata": {
        "id": "kyx--kINbc-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = client = create_connector(\n",
        "          key=db_key\n",
        "        )"
      ],
      "metadata": {
        "id": "bIhD89zFo0lY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Defining the Retrieval Logic\n",
        "\n",
        "The core of any RAG system is the retrieval mechanism. Here, we define the main functions for both of our RAG approaches.\n",
        "\n",
        "First, lets define the confgurations for our vector search system. We use Google's [`gemini-embedding-001`](https://ai.google.dev/gemini-api/docs/embeddings) embedding model here, with dimensions configured to 768 - same as our document embeddings' dimensions. It is necessary for these dimensions to match."
      ],
      "metadata": {
        "id": "YtHFpOQHbjso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GEMINI_MODEL_NAME = \"gemini-embedding-001\"\n",
        "EMBEDDING_DIMENSIONS = 768\n",
        "gemini_client = genai.Client(api_key=google_api_key)\n",
        "DESCRIPTOR_SET_NAME = \"entity_embeddings_gemini\""
      ],
      "metadata": {
        "id": "wotoO9RAo1-F"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both of our RAG methods will start with a vector search to find initial, semantically relevant entities. This function takes a user's query, embeds it using the `gemini-embedding-001` model, and performs a K-Nearest Neighbor (KNN) search in ApertureDB to find the most similar entities in our knowledge base.\n",
        "\n",
        "ApertureDB's ability to chain commands is powerful here: we first `FindDescriptor` to get the top K vectors, then immediately find the `Entity` connected to each vector via the `has_embedding` relationship, all in a single query."
      ],
      "metadata": {
        "id": "-GJ12X2ucNqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_semantic_entry_points(query_text: str, k: int, client, gemini_client) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Finds the top K most semantically relevant entities in the knowledge graph\n",
        "    based on a user query using vector search and graph traversal.\n",
        "    Uses Gemini for generating the embedding of the query.\n",
        "    \"\"\"\n",
        "    # Create Gemini embedding config\n",
        "    embed_cfg = types.EmbedContentConfig(\n",
        "        output_dimensionality=EMBEDDING_DIMENSIONS,\n",
        "        task_type=\"QUESTION_ANSWERING\",  # since it's will be used for Q&A. RETRIEVAL_QUERY can also be used here.\n",
        "    )\n",
        "\n",
        "    # Get embedding from Gemini\n",
        "    result = gemini_client.models.embed_content(\n",
        "        model=GEMINI_MODEL_NAME,\n",
        "        contents=[query_text],\n",
        "        config=embed_cfg,\n",
        "    )\n",
        "\n",
        "    # Extract embedding\n",
        "    query_embedding = result.embeddings[0].values\n",
        "    query_embedding_bytes = np.array(query_embedding, dtype=np.float32).tobytes()\n",
        "\n",
        "    # Execute a FindDescriptor KNN query and traverse to linked entities\n",
        "    query = [\n",
        "        {\n",
        "            \"FindDescriptor\": {\n",
        "                \"set\": DESCRIPTOR_SET_NAME,\n",
        "                \"k_neighbors\": k,\n",
        "                \"distances\": True,\n",
        "                \"blobs\": False,\n",
        "                \"results\": {\n",
        "                    \"all_properties\": True\n",
        "                },\n",
        "                \"_ref\": 1,\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"FindEntity\": {\n",
        "                \"is_connected_to\": {\n",
        "                    \"ref\": 1,\n",
        "                    \"connection_class\": \"has_embedding\",\n",
        "                },\n",
        "                \"results\": {\n",
        "                    \"all_properties\": True\n",
        "                },\n",
        "            }\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    response, _ = client.query(query, [query_embedding_bytes])\n",
        "\n",
        "    # Extract results\n",
        "    descriptor_results = response[0].get(\"FindDescriptor\", {}).get(\"entities\", [])\n",
        "    entity_results = response[1].get(\"FindEntity\", {}).get(\"entities\", [])\n",
        "\n",
        "    # Map descriptor -> class, entity -> full data\n",
        "    id_to_class_map = {\n",
        "        d.get('source_entity_id'): d.get('source_entity_class')\n",
        "        for d in descriptor_results\n",
        "    }\n",
        "    id_to_entity_data_map = {\n",
        "        e.get('id'): e\n",
        "        for e in entity_results\n",
        "    }\n",
        "\n",
        "    enriched_entities = []\n",
        "    for descriptor_item in descriptor_results:\n",
        "        entity_id = descriptor_item.get('source_entity_id')\n",
        "        if entity_id in id_to_entity_data_map:\n",
        "            entity_data = id_to_entity_data_map[entity_id].copy()\n",
        "            entity_data['class'] = id_to_class_map.get(entity_id)\n",
        "            enriched_entities.append(entity_data)\n",
        "\n",
        "    return enriched_entities"
      ],
      "metadata": {
        "id": "LuH5sf-npCtg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " A helper function to format retreived entities into a string to be passed as context into an LLM prompt."
      ],
      "metadata": {
        "id": "G7KQIEztcVRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _format_entity_properties(entity: Dict[str, Any]) -> str:\n",
        "    \"\"\"Helper to format entity properties into a string.\"\"\"\n",
        "    formatted_props = []\n",
        "    entity_name = entity.get('name', f\"Entity_{entity.get('id', 'Unknown')}\")\n",
        "    entity_class = entity.get('class', 'Unknown')\n",
        "\n",
        "    formatted_props.append(f\"Entity: '{entity_name}' (Class: '{entity_class}', ID: {entity.get('id', 'N/A')})\")\n",
        "\n",
        "    for key, value in entity.items():\n",
        "        if not key.startswith('_') and key not in ['name', 'class', 'id', '_uniqueid']:\n",
        "            if isinstance(value, (dict, list)):\n",
        "                value_str = str(value)\n",
        "            else:\n",
        "                value_str = str(value)\n",
        "            formatted_props.append(f\"  - {key}: {value_str}\")\n",
        "    return \"\\n\".join(formatted_props)"
      ],
      "metadata": {
        "id": "QsYVrzOQAp5L"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the key component of Graph RAG. Starting from the initial entities, this function traverses the graph outwards for a set number of `hops`, collecting connected entities and their relationships to build a rich, interconnected context."
      ],
      "metadata": {
        "id": "OijArLTtchcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_traversal_context(start_entities: List[Dict[str, Any]], max_hops: int, max_entities: int, client) -> str:\n",
        "    \"\"\"\n",
        "    Performs a bounded BFS graph traversal from start_entities, collecting\n",
        "    and formatting entities and connections into a context string.\n",
        "    \"\"\"\n",
        "    context_strings: List[str] = []\n",
        "\n",
        "    collected_entities: Dict[int, Dict[str, Any]] = {}\n",
        "    collected_connections: List[Dict[str, Any]] = []\n",
        "\n",
        "    explored_entity_ids: set = set()\n",
        "\n",
        "    frontier_ids_for_current_hop: List[int] = []\n",
        "\n",
        "    # Initialize the frontier with the starting entities\n",
        "    frontier_ids_for_current_hop: List[int] = []\n",
        "\n",
        "    for entity in start_entities:\n",
        "        entity_id = entity.get(\"id\")\n",
        "        if entity_id is None or entity_id in explored_entity_ids:\n",
        "            continue\n",
        "\n",
        "        # Add the starting entity to the context and mark as explored\n",
        "        context_strings.append(_format_entity_properties(entity))\n",
        "        explored_entity_ids.add(entity_id)\n",
        "        frontier_ids_for_current_hop.append(entity_id)\n",
        "        collected_entities[entity_id] = entity\n",
        "\n",
        "        if len(explored_entity_ids) >= max_entities:\n",
        "            break\n",
        "\n",
        "    # Perform BFS traversal up to max_hops\n",
        "    for hop in range(1, max_hops + 1):\n",
        "        if not frontier_ids_for_current_hop or len(explored_entity_ids) >= max_entities:\n",
        "            break\n",
        "\n",
        "        all_connections_this_hop: List[Dict[str, Any]] = []\n",
        "        queries_for_this_hop = []\n",
        "        # Build queries to find connections for entities in the current frontier\n",
        "        for i, entity_id in enumerate(frontier_ids_for_current_hop):\n",
        "            ref_id = i + 1\n",
        "            entity_class = collected_entities[entity_id].get('class', 'Unknown')\n",
        "            queries_for_this_hop.extend([\n",
        "                {\"FindEntity\": {\"with_class\": entity_class, \"constraints\": {\"id\": [\"==\", entity_id]}, \"_ref\": ref_id}},\n",
        "                {\"FindConnection\": {\"src\": ref_id, \"results\": {\"all_properties\": True}}},\n",
        "                {\"FindConnection\": {\"dst\": ref_id, \"results\": {\"all_properties\": True}}}\n",
        "            ])\n",
        "\n",
        "        # Execute the queries to find connections\n",
        "        responses, _ = client.query(queries_for_this_hop)\n",
        "\n",
        "        # Collect unique connections found in this hop\n",
        "        conn_uids_seen = set()\n",
        "        for resp_block in responses:\n",
        "            if \"FindConnection\" in resp_block and resp_block[\"FindConnection\"].get(\"connections\"):\n",
        "                for conn in resp_block[\"FindConnection\"][\"connections\"]:\n",
        "                    if conn[\"_uniqueid\"] not in conn_uids_seen:\n",
        "                        all_connections_this_hop.append(conn)\n",
        "                        conn_uids_seen.add(conn[\"_uniqueid\"])\n",
        "\n",
        "        collected_connections.extend(all_connections_this_hop)\n",
        "\n",
        "        # Map entity IDs to their classes from the connections\n",
        "        id_to_class_map = {}\n",
        "        for conn in all_connections_this_hop:\n",
        "            if conn.get('src_id') is not None and conn.get('src_class') is not None:\n",
        "                id_to_class_map[conn['src_id']] = conn['src_class']\n",
        "            if conn.get('dst_id') is not None and conn.get('dst_class') is not None:\n",
        "                id_to_class_map[conn['dst_id']] = conn['dst_class']\n",
        "\n",
        "        # Identify new entities to fetch in the next hop\n",
        "        unique_new_entity_ids_to_fetch = set()\n",
        "        for conn in all_connections_this_hop:\n",
        "            src_id = conn.get(\"src_id\")\n",
        "            dst_id = conn.get(\"dst_id\")\n",
        "\n",
        "            # If source is in current frontier and destination is not explored, add destination\n",
        "            if src_id in frontier_ids_for_current_hop and dst_id not in explored_entity_ids:\n",
        "                unique_new_entity_ids_to_fetch.add(dst_id)\n",
        "            # If destination is in current frontier and source is not explored, add source\n",
        "            elif dst_id in frontier_ids_for_current_hop and src_id not in explored_entity_ids:\n",
        "                unique_new_entity_ids_to_fetch.add(src_id)\n",
        "\n",
        "        next_frontier_ids = []\n",
        "        # Fetch new entities and add to context if within limits\n",
        "        if unique_new_entity_ids_to_fetch:\n",
        "            valid_ids_to_fetch = [id for id in list(unique_new_entity_ids_to_fetch) if id is not None]\n",
        "            if not valid_ids_to_fetch: continue\n",
        "\n",
        "            fetch_new_entities_query = [{\"FindEntity\": {\"constraints\": {\"id\": [\"in\", valid_ids_to_fetch]}, \"results\": {\"all_properties\": True}}}]\n",
        "            fetch_responses, _ = client.query(fetch_new_entities_query)\n",
        "\n",
        "            if fetch_responses and \"FindEntity\" in fetch_responses[0] and fetch_responses[0][\"FindEntity\"].get(\"entities\"):\n",
        "                for entity in fetch_responses[0][\"FindEntity\"][\"entities\"]:\n",
        "                    if len(explored_entity_ids) >= max_entities: break\n",
        "                    entity_id = entity.get(\"id\")\n",
        "                    if entity_id not in explored_entity_ids:\n",
        "                        # Add entity class from the map if available\n",
        "                        entity['class'] = id_to_class_map.get(entity_id, 'Unknown')\n",
        "\n",
        "                        collected_entities[entity_id] = entity\n",
        "                        explored_entity_ids.add(entity_id)\n",
        "                        next_frontier_ids.append(entity_id)\n",
        "                        context_strings.append(_format_entity_properties(entity))\n",
        "\n",
        "        # Format and add connections to the context\n",
        "        for conn in all_connections_this_hop:\n",
        "            src_id = conn.get(\"src_id\")\n",
        "            dst_id = conn.get(\"dst_id\")\n",
        "\n",
        "            # Only add connection string if both entities are in the cache (meaning they were added to context)\n",
        "            if src_id in collected_entities and dst_id in collected_entities:\n",
        "                src_entity, dst_entity = collected_entities[src_id], collected_entities[dst_id]\n",
        "                conn_class = conn.get(\"class\") or conn.get(\"type\", \"related_to\")\n",
        "                conn_str = f\"  - [{src_entity.get('name')}] --({conn_class})--> [{dst_entity.get('name')}]\"\n",
        "                if conn_str not in context_strings:\n",
        "                    context_strings.append(conn_str)\n",
        "\n",
        "        # Update the frontier for the next hop\n",
        "        frontier_ids_for_current_hop = next_frontier_ids\n",
        "\n",
        "    # Return the structured data along with the formatted string\n",
        "    return (\"\\n\".join(context_strings), collected_entities, collected_connections)"
      ],
      "metadata": {
        "id": "BGqErwr1pptB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function combines the semantic search and graph traversal steps into a single pipeline. It returns both the formatted text for the LLM and the structured data for visualization."
      ],
      "metadata": {
        "id": "Nf4XObUleJMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def graph_rag(query_text: str, k: int, max_hops: int, max_entities: int, client, gemini_client) -> tuple:\n",
        "    \"\"\"\n",
        "    Performs a full Graph RAG retrieval.\n",
        "\n",
        "    It first finds the top-k semantically similar entities, then performs a\n",
        "    bounded graph traversal from those entry points to build a rich,\n",
        "    interconnected context string.\n",
        "\n",
        "    Returns a tuple containing:\n",
        "    1. The formatted context string for the LLM.\n",
        "    2. A dictionary of the entity objects found.\n",
        "    3. A list of the connection objects found.\n",
        "    \"\"\"\n",
        "    # Find the top K most relevant entry points in the graph.\n",
        "    start_entities = find_semantic_entry_points(query_text, k, client, gemini_client)\n",
        "\n",
        "    # Build the final context string by traversing the graph from those entry points.\n",
        "    return build_traversal_context(\n",
        "        start_entities=start_entities,\n",
        "        max_hops=max_hops,\n",
        "        max_entities=max_entities,\n",
        "        client=client\n",
        "    )"
      ],
      "metadata": {
        "id": "0uXydDNWY2bg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's run a test query. We'll start with `k=3` initial entities and traverse `2` hops, up to a maximum of `20` total entities. The output context includes both entity properties and the relationships between them."
      ],
      "metadata": {
        "id": "370l6YhOeMXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What does a hypervisor do?\"\n",
        "k_initial_entities = 3 # The number of initial entities to find\n",
        "max_hops_config = 2 # The maximum depth for the traversal\n",
        "max_entities_context_limit = 20 # The hard limit on the total number of entities\n",
        "\n",
        "graph_rag_context, retrieved_entities, retrieved_connections = graph_rag(\n",
        "    query_text=query,\n",
        "    k=k_initial_entities,\n",
        "    max_hops=max_hops_config,\n",
        "    max_entities=max_entities_context_limit,\n",
        "    client=client,\n",
        "    gemini_client=gemini_client\n",
        ")\n",
        "\n",
        "print(\"--- Generated Graph RAG Context ---\")\n",
        "print(graph_rag_context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nx6zfQQK59s3",
        "outputId": "568b4583-a58b-45f7-ad94-effb0777cf62"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Generated Graph RAG Context ---\n",
            "Entity: 'Hypervisor' (Class: 'Hypervisor', ID: 223)\n",
            "  - definition: a software layer that allows multiple virtual machines (VMs) to run on a single physical machine by abstracting hardware resources.\n",
            "  - key_feature: VM Process Isolation (Kernel-Level), Device Mediation & Access Control, Direct Execution of Commands from VMs\n",
            "  - responsibility: Process Isolation, Resource Management, Virtual Machine Execution, Hardware Access Control\n",
            "Entity: 'hypervisors' (Class: 'Hypervisor', ID: 222)\n",
            "  - responsibility: create and manage virtual machines.\n",
            "Entity: 'Hypervisors' (Class: 'Hypervisor', ID: 236)\n",
            "  - responsibility: manage VM isolation\n",
            "  - security_aspect: manage VM isolation\n",
            "Entity: 'KVM (Kernel-based Virtual Machine)' (Class: 'Hypervisor', ID: 233)\n",
            "  - definition: Open-source Linux hypervisor.\n",
            "  - key_feature: Allows direct access to hardware.\n",
            "  - type: Type 1\n",
            "  - usage_context: Default hypervisor in Linux-based cloud environments.\n",
            "Entity: 'VMs' (Class: 'Computing System', ID: 10)\n",
            "  - scalability_aspect: can be migrated easily compared to physical machines.\n",
            "Entity: 'Operating System (OS)' (Class: 'Computing System', ID: 17)\n",
            "  - component_type: Operating System (OS)\n",
            "Entity: 'AWS' (Class: 'Cloud Service Provider', ID: 41)\n",
            "  - availability_factor: Auto-scaling ensures availability\n",
            "  - flexibility_option: choosing data center locations and storage options\n",
            "  - global_infrastructure: CloudFront speeds up content delivery globally\n",
            "  - market_position: 95-96% of cloud infrastructure belongs to a few major companies like: AWS\n",
            "  - performance_optimization: CloudFront speeds up content delivery globally\n",
            "  - security_priority: top priority\n",
            "  - service_offering_type: bare metal as EC2 instances along with other services similar to OpenStack\n",
            "Entity: 'Virtual Machine (VM)' (Class: 'Cloud Compute Resource', ID: 54)\n",
            "  - definition: VM inside it, demonstrating logical isolation\n",
            "Entity: 'Dedicated EC2' (Class: 'Cloud Compute Resource', ID: 57)\n",
            "  - variant: Provides physical isolation, bypassing the hypervisor\n",
            "Entity: 'VM' (Class: 'Cloud Compute Resource', ID: 67)\n",
            "Entity: 'Virtualization' (Class: 'Virtualization Technology', ID: 95)\n",
            "  - approach: Multiplexing, Aggregation, Emulation\n",
            "  - benefit: Optimizes computing power, storage, and network resources; enables easy migration of virtual machines; allows multiple applications on a single physical resource; reduces the need for physical hardware.\n",
            "  - cloud_computing_enabler: Most cloud computing infrastructures rely on virtualization since it is a common characteristic that helps achieve essential cloud features.\n",
            "  - cost_saving: Reduces the need for physical hardware.\n",
            "  - definition: allows multiple applications to run on a single physical resource.\n",
            "  - flexibility: Virtualization allows multiple applications to run on a single physical resource.\n",
            "  - implementation_level: Server/Machine Virtualization, Network Virtualization, I/O Virtualization\n",
            "  - migration_ease: Virtual machines (VMs) can be migrated easily compared to physical machines.\n",
            "  - purpose: Optimizes computing power, storage, and network resources.\n",
            "  - resource_optimization: Optimizes computing power, storage, and network resources.\n",
            "  - type: Hardware-Level Virtualization, System-Level Virtualization, Application-Level Virtualization, Nested Virtualization, Memory Virtualization\n",
            "Entity: 'Live Migration' (Class: 'Virtualization Technology', ID: 114)\n",
            "  - definition: Moving a running VM from one server to another without downtime.\n",
            "  - migration_ease: Moving a running VM from one server to another without downtime.\n",
            "Entity: 'Snapshot & Backup' (Class: 'Virtualization Technology', ID: 115)\n",
            "  - definition: VMs can take periodic snapshots to restore state in case of failures.\n",
            "Entity: 'Para-Virtualization' (Class: 'Virtualization Technology', ID: 117)\n",
            "  - approach: Hypervisor provides a specialized interface that does not exist in physical hardware.\n",
            "  - resource_optimization: Performance optimization due to lower overhead.\n",
            "  - type: Para-Virtualization\n",
            "Entity: 'Virtual Machines (VMs)' (Class: 'Virtualization Technology', ID: 118)\n",
            "  - definition: contain a full-fledged OS and take up several GBs.\n",
            "  - type: Virtual Machines (VMs)\n",
            "Entity: 'Compute Node' (Class: 'OpenStack Node', ID: 274)\n",
            "  - role: Runs virtual machines (VMs) using a hypervisor (e.g., KVM), Manages VM execution and resource allocation\n",
            "  - type: Compute Node\n",
            "  - [Hypervisor] --(allows_to_run)--> [Virtual Machines (VMs)]\n",
            "  - [Hypervisor] --(provides_interface_for)--> [Para-Virtualization]\n",
            "  - [Hypervisor] --(allocates_resources_to)--> [Virtual Machines (VMs)]\n",
            "  - [Hypervisor] --(allows_to_interact_with)--> [Virtual Machines (VMs)]\n",
            "  - [Hypervisor] --(manages_input_from)--> [VM]\n",
            "  - [Hypervisor] --(exposes_interface_to)--> [Virtual Machine (VM)]\n",
            "  - [VMs] --(runs_on)--> [Hypervisor]\n",
            "  - [KVM (Kernel-based Virtual Machine)] --(is_a)--> [Hypervisor]\n",
            "  - [Compute Node] --(uses)--> [Hypervisor]\n",
            "  - [Virtual Machines (VMs)] --(managed_by)--> [Hypervisor]\n",
            "  - [VM] --(sends_commands_through)--> [Hypervisor]\n",
            "  - [VMs] --(routes_instructions_through)--> [Hypervisor]\n",
            "  - [Dedicated EC2] --(bypasses)--> [Hypervisor]\n",
            "  - [Operating System (OS)] --(communicates_with)--> [Hypervisor]\n",
            "  - [hypervisors] --(manages)--> [Virtual Machines (VMs)]\n",
            "  - [hypervisors] --(creates)--> [Virtual Machines (VMs)]\n",
            "  - [Virtualization] --(utilized_by)--> [hypervisors]\n",
            "  - [VMs] --(runs_on)--> [hypervisors]\n",
            "  - [Hypervisors] --(supports)--> [Live Migration]\n",
            "  - [Hypervisors] --(supports)--> [Snapshot & Backup]\n",
            "  - [Hypervisors] --(manages_isolation_of)--> [VMs]\n",
            "  - [AWS] --(uses)--> [Hypervisors]\n",
            "Entity: 'Conceptual/Logical Architecture' (Class: 'Application Architecture', ID: 220)\n",
            "  - characteristic: Defines how a VM is launched; Identifies services involved; Focuses on distributed services.\n",
            "  - type: Conceptual/Logical Architecture\n",
            "Entity: 'Type 1 Hypervisor (Bare Metal)' (Class: 'Hypervisor', ID: 224)\n",
            "  - definition: Runs directly on hardware.\n",
            "  - example: VMware ESXi, KVM, Xen\n",
            "  - type: Type 1 Hypervisor\n",
            "  - usage_context: Highly scalable and efficient\n",
            "Entity: 'Type 2 Hypervisor (Hosted)' (Class: 'Hypervisor', ID: 225)\n",
            "  - definition: Runs on top of an existing OS.\n",
            "  - example: VirtualBox, VMware Workstation\n",
            "  - type: Type 2 Hypervisor\n",
            "  - usage_context: Less scalable but easier to deploy.\n",
            "Entity: 'KVM' (Class: 'Hypervisor', ID: 227)\n",
            "  - type: Type 1 Hypervisor\n",
            "  - usage_context: default\n",
            "  - [KVM (Kernel-based Virtual Machine)] --(is_an_example_of)--> [Type 1 Hypervisor (Bare Metal)]\n",
            "  - [KVM (Kernel-based Virtual Machine)] --(runs_alongside)--> [Operating System (OS)]\n",
            "  - [VMs] --(has_component)--> [Operating System (OS)]\n",
            "  - [VMs] --(contains)--> [Operating System (OS)]\n",
            "  - [Operating System (OS)] --(manages_hardware_access_for)--> [Type 2 Hypervisor (Hosted)]\n",
            "  - [Operating System (OS)] --(requires_modification_of)--> [Para-Virtualization]\n",
            "  - [Type 2 Hypervisor (Hosted)] --(runs_on)--> [Operating System (OS)]\n",
            "  - [Type 2 Hypervisor (Hosted)] --(runs_on_top_of)--> [Operating System (OS)]\n",
            "  - [Virtual Machines (VMs)] --(contains)--> [Operating System (OS)]\n",
            "  - [Virtualization] --(enables_virtualization_of)--> [Operating System (OS)]\n",
            "  - [Live Migration] --(moves)--> [VM]\n",
            "  - [Compute Node] --(manages_execution_of)--> [VM]\n",
            "  - [Compute Node] --(manages_resource_allocation_for)--> [VM]\n",
            "  - [Conceptual/Logical Architecture] --(defines_process_for)--> [VM]\n",
            "  - [Virtualization] --(has_model)--> [Para-Virtualization]\n",
            "  - [Compute Node] --(uses)--> [KVM]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets invoke gemini-2.5-flash LLM with the query and the retrieved context to produce the final answer.\n"
      ],
      "metadata": {
        "id": "KVz04x-jeQBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = gemini_client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=f\"Use the given context to answer the user's query. \\nQuery: {query}, \\nRetrieved Contex: {graph_rag_context}\"\n",
        ")\n",
        "\n",
        "answer = (response.text)\n",
        "\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vKNIFHMn1zok",
        "outputId": "051e3c49-e8ff-4ebb-b6a1-815f979104c8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A hypervisor is a software layer that enables multiple virtual machines (VMs) to run on a single physical machine by abstracting hardware resources.\n",
            "\n",
            "Its core functions include:\n",
            "*   **Creating and Managing VMs**: It creates and oversees the operation of virtual machines.\n",
            "*   **Resource Management**: It manages and allocates resources (like CPU, memory, and storage) to the VMs.\n",
            "*   **VM Execution**: It facilitates the execution of VMs and their direct interaction with hardware commands.\n",
            "*   **Hardware Access Control**: It controls how VMs access the underlying physical hardware.\n",
            "*   **VM Isolation**: It ensures process isolation between VMs, managing their security and preventing interference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explainability\n",
        "A key advantage of Graph RAG is explainability. This function uses the structured data returned from the pipeline to visualize the exact subgraph used for context generation.\n"
      ],
      "metadata": {
        "id": "Uzy5pVfrec2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import graphviz\n",
        "from IPython.display import display\n",
        "\n",
        "def visualize_from_data(\n",
        "    entities: Dict[int, Dict[str, Any]],\n",
        "    connections: List[Dict[str, Any]]\n",
        "):\n",
        "    \"\"\"\n",
        "    Generates and displays a graph visualization from pre-fetched entity and connection data.\n",
        "\n",
        "    \"\"\"\n",
        "    dot = graphviz.Digraph('RetrievedContext', comment='Subgraph used for RAG')\n",
        "    dot.attr('node', shape='box', style='rounded,filled', fillcolor='#E3F2FD', fontname=\"Helvetica\")\n",
        "    dot.attr('edge', color='#546E7A', fontsize='10', fontname=\"Helvetica\")\n",
        "    dot.attr(rankdir='TB', splines='true')\n",
        "\n",
        "    if not entities:\n",
        "        print(\"No data to visualize.\")\n",
        "        return\n",
        "\n",
        "    # Add all entities as nodes\n",
        "    for entity_id, props in entities.items():\n",
        "        label = props.get('name', f\"ID:{entity_id}\")\n",
        "        dot.node(str(entity_id), label)\n",
        "\n",
        "    # Add all connections as edges\n",
        "    for conn in connections:\n",
        "        src_id = conn.get(\"src_id\")\n",
        "        dst_id = conn.get(\"dst_id\")\n",
        "        # Ensure we only draw edges for nodes that are actually in our entity list\n",
        "        if src_id in entities and dst_id in entities:\n",
        "            conn_class = conn.get(\"class\") or conn.get(\"type\", \"related_to\")\n",
        "            dot.edge(str(src_id), str(dst_id), label=conn_class)\n",
        "\n",
        "    print(\"--- Retrieved Subgraph (Explainability View) ---\")\n",
        "    display(dot)"
      ],
      "metadata": {
        "id": "fagMEwlMfsLt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling the function shows the cluster of concepts the system retrieved to answer the query.\n"
      ],
      "metadata": {
        "id": "dTF19RkReixG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_from_data(retrieved_entities, retrieved_connections)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "id": "m8oxfv3Vfp9k",
        "outputId": "3be9cd15-c05d-4081-931b-184a06b02ab7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Retrieved Subgraph (Explainability View) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: RetrievedContext Pages: 1 -->\n<svg width=\"2822pt\" height=\"542pt\"\n viewBox=\"0.00 0.00 2822.00 542.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 538)\">\n<title>RetrievedContext</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-538 2818,-538 2818,4 -4,4\"/>\n<!-- 223 -->\n<g id=\"node1\" class=\"node\">\n<title>223</title>\n<path fill=\"#e3f2fd\" stroke=\"black\" d=\"M1392.5,-285C1392.5,-285 1335.5,-285 1335.5,-285 1329.5,-285 1323.5,-279 1323.5,-273 1323.5,-273 1323.5,-261 1323.5,-261 1323.5,-255 1329.5,-249 1335.5,-249 1335.5,-249 1392.5,-249 1392.5,-249 1398.5,-249 1404.5,-255 1404.5,-261 1404.5,-261 1404.5,-273 1404.5,-273 1404.5,-279 1398.5,-285 1392.5,-285\"/>\n<text text-anchor=\"middle\" x=\"1364\" y=\"-263.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Hypervisor</text>\n</g>\n<!-- 54 -->\n<g id=\"node8\" class=\"node\">\n<title>54</title>\n<path fill=\"#e3f2fd\" stroke=\"black\" d=\"M1551,-202C1551,-202 1431,-202 1431,-202 1425,-202 1419,-196 1419,-190 1419,-190 1419,-178 1419,-178 1419,-172 1425,-166 1431,-166 1431,-166 1551,-166 1551,-166 1557,-166 1563,-172 1563,-178 1563,-178 1563,-190 1563,-190 1563,-196 1557,-202 1551,-202\"/>\n<text text-anchor=\"middle\" x=\"1491\" y=\"-180.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Virtual Machine (VM)</text>\n</g>\n<!-- 223&#45;&gt;54 -->\n<g id=\"edge6\" class=\"edge\">\n<title>223&#45;&gt;54</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1404.66,-257.28C1422.93,-251.91 1443.93,-243.57 1460,-231 1466.83,-225.66 1472.69,-218.39 1477.41,-211.21\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1480.61,-212.68 1482.78,-202.3 1474.62,-209.06 1480.61,-212.68\"/>\n<text text-anchor=\"middle\" x=\"1517\" y=\"-223\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">exposes_interface_to</text>\n</g>\n<!-- 223&#45;&gt;54 -->\n<g id=\"edge40\" class=\"edge\">\n<title>223&#45;&gt;54</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1404.92,-260.35C1462.95,-252.14 1562.76,-237.22 1568,-231 1575.92,-221.61 1571.64,-213.63 1561.93,-207.1\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1563.55,-203.99 1553.11,-202.16 1560.13,-210.1 1563.55,-203.99\"/>\n<text text-anchor=\"middle\" x=\"1619\" y=\"-223\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">exposes_interface_to</text>\n</g>\n<!-- 67 -->\n<g id=\"node10\" class=\"node\">\n<title>67</title>\n<path fill=\"#e3f2fd\" stroke=\"black\" d=\"M2220,-202C2220,-202 2190,-202 2190,-202 2184,-202 2178,-196 2178,-190 2178,-190 2178,-178 2178,-178 2178,-172 2184,-166 2190,-166 2190,-166 2220,-166 2220,-166 2226,-166 2232,-172 2232,-178 2232,-178 2232,-190 2232,-190 2232,-196 2226,-202 2220,-202\"/>\n<text text-anchor=\"middle\" x=\"2205\" y=\"-180.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">VM</text>\n</g>\n<!-- 223&#45;&gt;67 -->\n<g id=\"edge5\" class=\"edge\">\n<title>223&#45;&gt;67</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1404.53,-259.92C1429.43,-256.35 1462.01,-251.97 1491,-249 1603.14,-237.52 1635.02,-259.82 1744,-231 1754.95,-228.1 1756.06,-222.95 1767,-220 1842.2,-199.76 2076.04,-189.54 2167.65,-186.23\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"2167.97,-189.73 2177.84,-185.87 2167.73,-182.73 2167.97,-189.73\"/>\n<text text-anchor=\"middle\" x=\"1812.5\" y=\"-223\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">manages_input_from</text>\n</g>\n<!-- 223&#45;&gt;67 -->\n<g id=\"edge43\" class=\"edge\">\n<title>223&#45;&gt;67</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1404.51,-259.69C1429.4,-256.04 1461.98,-251.65 1491,-249 1572.32,-241.58 1779.68,-254.11 1858,-231 1867.36,-228.24 1867.72,-223.03 1877,-220 1930.19,-202.64 2093.26,-191.39 2167.49,-187.04\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"2168,-190.51 2177.78,-186.44 2167.59,-183.53 2168,-190.51\"/>\n<text text-anchor=\"middle\" x=\"1922.5\" y=\"-223\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">manages_input_from</text>\n</g>\n<!-- 117 -->\n<g id=\"node14\" class=\"node\">\n<title>117</title>\n<path fill=\"#e3f2fd\" stroke=\"black\" d=\"M400.5,-36C400.5,-36 297.5,-36 297.5,-36 291.5,-36 285.5,-30 285.5,-24 285.5,-24 285.5,-12 285.5,-12 285.5,-6 291.5,0 297.5,0 297.5,0 400.5,0 400.5,0 406.5,0 412.5,-6 412.5,-12 412.5,-12 412.5,-24 412.5,-24 412.5,-30 406.5,-36 400.5,-36\"/>\n<text text-anchor=\"middle\" x=\"349\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Para&#45;Virtualization</text>\n</g>\n<!-- 223&#45;&gt;117 -->\n<g id=\"edge2\" class=\"edge\">\n<title>223&#45;&gt;117</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1323.4,-265.25C1109.42,-261.24 121.82,-242.13 111,-231 38.25,-156.19 201.82,-76.56 293.03,-39.8\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"294.43,-43.01 302.43,-36.06 291.84,-36.51 294.43,-43.01\"/>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-140\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">provides_interface_for</text>\n</g>\n<!-- 223&#45;&gt;117 -->\n<g id=\"edge52\" class=\"edge\">\n<title>223&#45;&gt;117</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1323.1,-265.34C1180.56,-262.87 710.81,-253.11 647,-231 530.78,-190.73 419.82,-90.01 372.7,-43.39\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"374.98,-40.72 365.43,-36.13 370.03,-45.67 374.98,-40.72\"/>\n<text text-anchor=\"middle\" x=\"542.5\" y=\"-140\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">provides_interface_for</text>\n</g>\n<!-- 118 -->\n<g id=\"node15\" class=\"node\">\n<title>118</title>\n<path fill=\"#e3f2fd\" stroke=\"black\" d=\"M881,-202C881,-202 747,-202 747,-202 741,-202 735,-196 735,-190 735,-190 735,-178 735,-178 735,-172 741,-166 747,-166 747,-166 881,-166 881,-166 887,-166 893,-172 893,-178 893,-178 893,-190 893,-190 893,-196 887,-202 881,-202\"/>\n<text text-anchor=\"middle\" x=\"814\" y=\"-180.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Virtual Machines (VMs)</text>\n</g>\n<!-- 223&#45;&gt;118 -->\n<g id=\"edge1\" class=\"edge\">\n<title>223&#45;&gt;118</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1323.42,-265.52C1176.54,-263.58 680.09,-255.26 657,-231 630.48,-203.14 675.95,-191.88 724.67,-187.46\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"725.08,-190.94 734.76,-186.64 724.51,-183.96 725.08,-190.94\"/>\n<text text-anchor=\"middle\" x=\"687.5\" y=\"-223\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">allows_to_run</text>\n</g>\n<!-- 223&#45;&gt;118 -->\n<g id=\"edge3\" class=\"edge\">\n<title>223&#45;&gt;118</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1323.19,-265.23C1187.82,-262.49 761.02,-252.18 741,-231 732.39,-221.89 737.21,-213.82 747.59,-207.09\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"749.41,-210.08 756.49,-202.2 746.04,-203.95 749.41,-210.08\"/>\n<text text-anchor=\"middle\" x=\"791.5\" y=\"-223\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">allocates_resources_to</text>\n</g>\n<!-- 223&#45;&gt;118 -->\n<g id=\"edge4\" class=\"edge\">\n<title>223&#45;&gt;118</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1323.37,-266.52C1219.61,-267.33 947.22,-265.95 865,-231 853.63,-226.17 843.1,-217.71 834.61,-209.35\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"837.13,-206.93 827.69,-202.13 832.08,-211.77 837.13,-206.93\"/>\n<text text-anchor=\"middle\" x=\"916.5\" y=\"-223\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">allows_to_interact_with</text>\n</g>\n<!-- 223&#45;&gt;118 -->\n<g id=\"edge56\" class=\"edge\">\n<title>223&#45;&gt;118</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1323.42,-266.81C1253.99,-267.17 1108.54,-263.51 991,-231 980.08,-227.98 978.7,-223.72 968,-220 947.34,-212.81 924.6,-206.71 903.08,-201.7\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"903.82,-198.28 893.3,-199.48 902.27,-205.11 903.82,-198.28\"/>\n<text text-anchor=\"middle\" x=\"1021.5\" y=\"-223\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">allows_to_run</text>\n</g>\n<!-- 223&#45;&gt;118 -->\n<g id=\"edge57\" class=\"edge\">\n<title>223&#45;&gt;118</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1323.44,-265.22C1266.76,-263.21 1161.13,-256.08 1075,-231 1064.12,-227.83 1062.84,-223.31 1052,-220 1003.91,-205.33 948.41,-196.72 903.11,-191.71\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"903.33,-188.21 893.01,-190.63 902.59,-195.17 903.33,-188.21\"/>\n<text text-anchor=\"middle\" x=\"1125.5\" y=\"-223\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">allocates_resources_to</text>\n</g>\n<!-- 223&#45;&gt;118 -->\n<g id=\"edge58\" class=\"edge\">\n<title>223&#45;&gt;118</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1323.36,-261.31C1288.47,-256.41 1237.27,-247.13 1195,-231 1185.88,-227.52 1185.29,-222.98 1176,-220 1127.01,-204.28 993.69,-194.39 903.26,-189.28\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"903.19,-185.77 893.01,-188.71 902.8,-192.76 903.19,-185.77\"/>\n<text text-anchor=\"middle\" x=\"1246.5\" y=\"-223\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">allows_to_interact_with</text>\n</g>\n<!-- 222 -->\n<g id=\"node2\" class=\"node\">\n<title>222</title>\n<path fill=\"#e3f2fd\" stroke=\"black\" d=\"M504,-285C504,-285 442,-285 442,-285 436,-285 430,-279 430,-273 430,-273 430,-261 430,-261 430,-255 436,-249 442,-249 442,-249 504,-249 504,-249 510,-249 516,-255 516,-261 516,-261 516,-273 516,-273 516,-279 510,-285 504,-285\"/>\n<text text-anchor=\"middle\" x=\"473\" y=\"-263.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">hypervisors</text>\n</g>\n<!-- 222&#45;&gt;118 -->\n<g id=\"edge15\" class=\"edge\">\n<title>222&#45;&gt;118</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M511.84,-248.9C535.25,-239.18 565.88,-227.5 594,-220 636.37,-208.7 684.37,-200.55 724.7,-194.97\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"725.34,-198.41 734.78,-193.6 724.4,-191.48 725.34,-198.41\"/>\n<text text-anchor=\"middle\" x=\"614\" y=\"-223\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">manages</text>\n</g>\n<!-- 222&#45;&gt;118 -->\n<g id=\"edge16\" class=\"edge\">\n<title>222&#45;&gt;118</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M429.77,-256.3C403.99,-248.58 378.96,-236.35 394,-220 415.9,-196.19 607.97,-188.58 724.65,-186.14\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"724.73,-189.64 734.66,-185.94 724.59,-182.64 724.73,-189.64\"/>\n<text text-anchor=\"middle\" x=\"410.5\" y=\"-223\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">creates</text>\n</g>\n<!-- 222&#45;&gt;118 -->\n<g id=\"edge54\" class=\"edge\">\n<title>222&#45;&gt;118</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M455.38,-248.9C447.89,-239.6 442.44,-228.33 450,-220 468.13,-200.04 622.55,-191.16 724.35,-187.44\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"724.78,-190.93 734.65,-187.08 724.53,-183.93 724.78,-190.93\"/>\n<text text-anchor=\"middle\" x=\"470\" y=\"-223\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">manages</text>\n</g>\n<!-- 222&#45;&gt;118 -->\n<g id=\"edge55\" class=\"edge\">\n<title>222&#45;&gt;118</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M487.22,-248.67C496.56,-238.54 509.67,-226.52 524,-220 558.7,-204.21 652.68,-194.9 724.33,-189.9\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"724.99,-193.36 734.73,-189.19 724.52,-186.37 724.99,-193.36\"/>\n<text text-anchor=\"middle\" x=\"540.5\" y=\"-223\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">creates</text>\n</g>\n<!-- 236 -->\n<g id=\"node3\" class=\"node\">\n<title>236</title>\n<path fill=\"#e3f2fd\" stroke=\"black\" d=\"M1738,-451C1738,-451 1674,-451 1674,-451 1668,-451 1662,-445 1662,-439 1662,-439 1662,-427 1662,-427 1662,-421 1668,-415 1674,-415 1674,-415 1738,-415 1738,-415 1744,-415 1750,-421 1750,-427 1750,-427 1750,-439 1750,-439 1750,-445 1744,-451 1738,-451\"/>\n<text text-anchor=\"middle\" x=\"1706\" y=\"-429.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Hypervisors</text>\n</g>\n<!-- 10 -->\n<g id=\"node5\" class=\"node\">\n<title>10</title>\n<path fill=\"#e3f2fd\" stroke=\"black\" d=\"M1024,-368C1024,-368 994,-368 994,-368 988,-368 982,-362 982,-356 982,-356 982,-344 982,-344 982,-338 988,-332 994,-332 994,-332 1024,-332 1024,-332 1030,-332 1036,-338 1036,-344 1036,-344 1036,-356 1036,-356 1036,-362 1030,-368 1024,-368\"/>\n<text text-anchor=\"middle\" x=\"1009\" y=\"-346.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">VMs</text>\n</g>\n<!-- 236&#45;&gt;10 -->\n<g id=\"edge21\" class=\"edge\">\n<title>236&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1661.8,-428.13C1594.74,-422.14 1463.34,-409.97 1352,-397 1240.58,-384.02 1109.25,-365.51 1046.3,-356.44\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1046.48,-352.92 1036.08,-354.96 1045.48,-359.85 1046.48,-352.92\"/>\n<text text-anchor=\"middle\" x=\"1399.5\" y=\"-389\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">manages_isolation_of</text>\n</g>\n<!-- 236&#45;&gt;10 -->\n<g id=\"edge31\" class=\"edge\">\n<title>236&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1661.74,-422.8C1610.34,-412.43 1522.87,-395.75 1447,-386 1299.34,-367.03 1122.28,-356.64 1046.45,-352.78\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1046.17,-349.26 1036.01,-352.25 1045.82,-356.25 1046.17,-349.26\"/>\n<text text-anchor=\"middle\" x=\"1565.5\" y=\"-389\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">manages_isolation_of</text>\n</g>\n<!-- 114 -->\n<g id=\"node12\" class=\"node\">\n<title>114</title>\n<path fill=\"#e3f2fd\" stroke=\"black\" d=\"M1909.5,-368C1909.5,-368 1832.5,-368 1832.5,-368 1826.5,-368 1820.5,-362 1820.5,-356 1820.5,-356 1820.5,-344 1820.5,-344 1820.5,-338 1826.5,-332 1832.5,-332 1832.5,-332 1909.5,-332 1909.5,-332 1915.5,-332 1921.5,-338 1921.5,-344 1921.5,-344 1921.5,-356 1921.5,-356 1921.5,-362 1915.5,-368 1909.5,-368\"/>\n<text text-anchor=\"middle\" x=\"1871\" y=\"-346.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Live Migration</text>\n</g>\n<!-- 236&#45;&gt;114 -->\n<g id=\"edge19\" class=\"edge\">\n<title>236&#45;&gt;114</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1740.99,-414.82C1766.12,-402.48 1800.18,-385.77 1827.13,-372.54\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1828.91,-375.56 1836.34,-368.01 1825.82,-369.28 1828.91,-375.56\"/>\n<text text-anchor=\"middle\" x=\"1817\" y=\"-389\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">supports</text>\n</g>\n<!-- 236&#45;&gt;114 -->\n<g id=\"edge50\" class=\"edge\">\n<title>236&#45;&gt;114</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1750.07,-428.47C1777.97,-424.41 1813.62,-415.7 1840,-397 1847.18,-391.91 1853.19,-384.59 1857.94,-377.28\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1861.23,-378.59 1863.29,-368.2 1855.2,-375.04 1861.23,-378.59\"/>\n<text text-anchor=\"middle\" x=\"1869\" y=\"-389\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">supports</text>\n</g>\n<!-- 115 -->\n<g id=\"node13\" class=\"node\">\n<title>115</title>\n<path fill=\"#e3f2fd\" stroke=\"black\" d=\"M1790.5,-368C1790.5,-368 1679.5,-368 1679.5,-368 1673.5,-368 1667.5,-362 1667.5,-356 1667.5,-356 1667.5,-344 1667.5,-344 1667.5,-338 1673.5,-332 1679.5,-332 1679.5,-332 1790.5,-332 1790.5,-332 1796.5,-332 1802.5,-338 1802.5,-344 1802.5,-344 1802.5,-356 1802.5,-356 1802.5,-362 1796.5,-368 1790.5,-368\"/>\n<text text-anchor=\"middle\" x=\"1735\" y=\"-346.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Snapshot &amp; Backup</text>\n</g>\n<!-- 236&#45;&gt;115 -->\n<g id=\"edge20\" class=\"edge\">\n<title>236&#45;&gt;115</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1685.03,-414.77C1677.26,-406.23 1671.52,-395.7 1677,-386 1679.44,-381.68 1682.64,-377.84 1686.3,-374.43\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1688.7,-376.99 1694.34,-368.02 1684.34,-371.52 1688.7,-376.99\"/>\n<text text-anchor=\"middle\" x=\"1696\" y=\"-389\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">supports</text>\n</g>\n<!-- 236&#45;&gt;115 -->\n<g id=\"edge51\" class=\"edge\">\n<title>236&#45;&gt;115</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1712.15,-414.82C1715.99,-404.08 1721.03,-390.03 1725.39,-377.84\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1728.78,-378.75 1728.86,-368.15 1722.19,-376.39 1728.78,-378.75\"/>\n<text text-anchor=\"middle\" x=\"1741\" y=\"-389\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">supports</text>\n</g>\n<!-- 233 -->\n<g id=\"node4\" class=\"node\">\n<title>233</title>\n<path fill=\"#e3f2fd\" stroke=\"black\" d=\"M1637.5,-368C1637.5,-368 1424.5,-368 1424.5,-368 1418.5,-368 1412.5,-362 1412.5,-356 1412.5,-356 1412.5,-344 1412.5,-344 1412.5,-338 1418.5,-332 1424.5,-332 1424.5,-332 1637.5,-332 1637.5,-332 1643.5,-332 1649.5,-338 1649.5,-344 1649.5,-344 1649.5,-356 1649.5,-356 1649.5,-362 1643.5,-368 1637.5,-368\"/>\n<text text-anchor=\"middle\" x=\"1531\" y=\"-346.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">KVM (Kernel&#45;based Virtual Machine)</text>\n</g>\n<!-- 233&#45;&gt;223 -->\n<g id=\"edge8\" class=\"edge\">\n<title>233&#45;&gt;223</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1495.58,-331.82C1470.15,-319.48 1435.68,-302.77 1408.4,-289.54\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1409.6,-286.23 1399.08,-285.01 1406.55,-292.53 1409.6,-286.23\"/>\n<text text-anchor=\"middle\" x=\"1466.5\" y=\"-306\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">is_a</text>\n</g>\n<!-- 233&#45;&gt;223 -->\n<g id=\"edge23\" class=\"edge\">\n<title>233&#45;&gt;223</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1515.47,-331.62C1506.04,-322 1493.29,-310.5 1480,-303 1459.83,-291.63 1435.56,-283.56 1414.45,-278.07\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1415.23,-274.65 1404.68,-275.64 1413.54,-281.45 1415.23,-274.65\"/>\n<text text-anchor=\"middle\" x=\"1504.5\" y=\"-306\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">is_a</text>\n</g>\n<!-- 17 -->\n<g id=\"node6\" class=\"node\">\n<title>17</title>\n<path fill=\"#e3f2fd\" stroke=\"black\" d=\"M881.5,-119C881.5,-119 746.5,-119 746.5,-119 740.5,-119 734.5,-113 734.5,-107 734.5,-107 734.5,-95 734.5,-95 734.5,-89 740.5,-83 746.5,-83 746.5,-83 881.5,-83 881.5,-83 887.5,-83 893.5,-89 893.5,-95 893.5,-95 893.5,-107 893.5,-107 893.5,-113 887.5,-119 881.5,-119\"/>\n<text text-anchor=\"middle\" x=\"814\" y=\"-97.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Operating System (OS)</text>\n</g>\n<!-- 233&#45;&gt;17 -->\n<g id=\"edge25\" class=\"edge\">\n<title>233&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1649.52,-332.93C1652.71,-332.6 1655.88,-332.29 1659,-332 1753.95,-323.1 2450.44,-354.26 2516,-285 2527,-273.38 2525.54,-261.84 2516,-249 2439.88,-146.51 2366.78,-187.85 2241,-166 1982.28,-121.06 1175.05,-106.68 903.88,-103.05\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"903.73,-99.54 893.68,-102.91 903.64,-106.54 903.73,-99.54\"/>\n<text text-anchor=\"middle\" x=\"2533\" y=\"-223\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">runs_alongside</text>\n</g>\n<!-- 224 -->\n<g id=\"node18\" class=\"node\">\n<title>224</title>\n<path fill=\"#e3f2fd\" stroke=\"black\" d=\"M1692,-285C1692,-285 1512,-285 1512,-285 1506,-285 1500,-279 1500,-273 1500,-273 1500,-261 1500,-261 1500,-255 1506,-249 1512,-249 1512,-249 1692,-249 1692,-249 1698,-249 1704,-255 1704,-261 1704,-261 1704,-273 1704,-273 1704,-279 1698,-285 1692,-285\"/>\n<text text-anchor=\"middle\" x=\"1602\" y=\"-263.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Type 1 Hypervisor (Bare Metal)</text>\n</g>\n<!-- 233&#45;&gt;224 -->\n<g id=\"edge24\" class=\"edge\">\n<title>233&#45;&gt;224</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1559.99,-331.94C1567.14,-326.81 1574.35,-320.73 1580,-314 1584.74,-308.35 1588.73,-301.51 1591.95,-294.84\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1595.29,-295.93 1596.11,-285.37 1588.88,-293.12 1595.29,-295.93\"/>\n<text text-anchor=\"middle\" x=\"1626.5\" y=\"-306\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">is_an_example_of</text>\n</g>\n<!-- 10&#45;&gt;223 -->\n<g id=\"edge7\" class=\"edge\">\n<title>10&#45;&gt;223</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1036.37,-347.72C1083.21,-344.98 1181.38,-336.81 1261,-314 1282.1,-307.96 1304.46,-298.39 1322.94,-289.54\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1324.5,-292.67 1331.95,-285.14 1321.43,-286.38 1324.5,-292.67\"/>\n<text text-anchor=\"middle\" x=\"1307.5\" y=\"-306\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">runs_on</text>\n</g>\n<!-- 10&#45;&gt;223 -->\n<g id=\"edge12\" class=\"edge\">\n<title>10&#45;&gt;223</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M981.76,-342.31C955.41,-334.61 921.68,-320.72 938,-303 962.97,-275.9 1205.66,-269.78 1313.18,-268.4\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1313.5,-271.9 1323.45,-268.28 1313.41,-264.9 1313.5,-271.9\"/>\n<text text-anchor=\"middle\" x=\"998.5\" y=\"-306\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">routes_instructions_through</text>\n</g>\n<!-- 10&#45;&gt;223 -->\n<g id=\"edge26\" class=\"edge\">\n<title>10&#45;&gt;223</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1033.58,-331.89C1050.62,-320.34 1071.98,-306.58 1082,-303 1159.2,-275.44 1254.99,-268.91 1312.71,-267.72\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1313.09,-271.22 1323.03,-267.56 1312.98,-264.22 1313.09,-271.22\"/>\n<text text-anchor=\"middle\" x=\"1099.5\" y=\"-306\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">runs_on</text>\n</g>\n<!-- 10&#45;&gt;223 -->\n<g id=\"edge30\" class=\"edge\">\n<title>10&#45;&gt;223</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1036.22,-341.91C1058.42,-335.71 1090.35,-325.87 1117,-314 1125.91,-310.03 1126.8,-306.24 1136,-303 1194.65,-282.35 1266.02,-273.87 1313.11,-270.4\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1313.63,-273.87 1323.36,-269.7 1313.15,-266.89 1313.63,-273.87\"/>\n<text text-anchor=\"middle\" x=\"1196.5\" y=\"-306\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">routes_instructions_through</text>\n</g>\n<!-- 10&#45;&gt;222 -->\n<g id=\"edge18\" class=\"edge\">\n<title>10&#45;&gt;222</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M981.68,-344.87C897.17,-332.1 638.93,-293.08 526.38,-276.07\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"526.68,-272.57 516.27,-274.54 525.64,-279.49 526.68,-272.57\"/>\n<text text-anchor=\"middle\" x=\"791.5\" y=\"-306\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">runs_on</text>\n</g>\n<!-- 10&#45;&gt;222 -->\n<g id=\"edge27\" class=\"edge\">\n<title>10&#45;&gt;222</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M981.6,-347.35C923.74,-343.61 784.95,-333.28 670,-314 620.77,-305.75 565.48,-292.48 526.04,-282.31\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"526.67,-278.86 516.11,-279.73 524.91,-285.63 526.67,-278.86\"/>\n<text text-anchor=\"middle\" x=\"687.5\" y=\"-306\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">runs_on</text>\n</g>\n<!-- 10&#45;&gt;17 -->\n<g id=\"edge28\" class=\"edge\">\n<title>10&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M981.9,-348.7C850.14,-347.1 281.63,-338.77 254,-314 191.6,-258.06 243.3,-172.96 319,-137 354.55,-120.11 591.57,-109.5 724.32,-104.81\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"724.61,-108.3 734.48,-104.45 724.36,-101.31 724.61,-108.3\"/>\n<text text-anchor=\"middle\" x=\"269\" y=\"-223\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">has_component</text>\n</g>\n<!-- 10&#45;&gt;17 -->\n<g id=\"edge29\" class=\"edge\">\n<title>10&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M981.82,-349.41C864.77,-350.47 407.04,-347.08 349,-231 313.9,-160.8 579.3,-124.25 724.11,-109.7\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"724.72,-113.16 734.32,-108.7 724.03,-106.2 724.72,-113.16\"/>\n<text text-anchor=\"middle\" x=\"367.5\" y=\"-223\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">contains</text>\n</g>\n<!-- 17&#45;&gt;223 -->\n<g id=\"edge14\" class=\"edge\">\n<title>17&#45;&gt;223</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M893.54,-103.46C1061.92,-107.4 1449,-121.18 1572,-166 1598.07,-175.5 1598.52,-188.94 1623,-202 1642.73,-212.53 1657.32,-201.57 1670,-220 1692.84,-253.2 1531.02,-244.31 1491,-249 1465.79,-251.95 1437.82,-255.65 1414.56,-258.84\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1413.99,-255.39 1404.57,-260.22 1414.95,-262.32 1413.99,-255.39\"/>\n<text text-anchor=\"middle\" x=\"1667\" y=\"-181.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">communicates_with</text>\n</g>\n<!-- 17&#45;&gt;223 -->\n<g id=\"edge34\" class=\"edge\">\n<title>17&#45;&gt;223</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M893.75,-101.48C1103.38,-100.97 1657.48,-105.41 1711,-166 1731.6,-189.32 1712.79,-217.01 1685,-231 1646.32,-250.46 1534.02,-244.13 1491,-249 1465.78,-251.86 1437.81,-255.54 1414.55,-258.76\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1413.98,-255.3 1404.56,-260.14 1414.94,-262.23 1413.98,-255.3\"/>\n<text text-anchor=\"middle\" x=\"1763\" y=\"-181.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">communicates_with</text>\n</g>\n<!-- 17&#45;&gt;117 -->\n<g id=\"edge33\" class=\"edge\">\n<title>17&#45;&gt;117</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M744.49,-82.96C721.97,-77.35 696.9,-71.01 674,-65 656.17,-60.32 652.09,-57.58 634,-54 562.84,-39.92 480.49,-30.54 422.67,-25.07\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"422.81,-21.56 412.53,-24.12 422.16,-28.53 422.81,-21.56\"/>\n<text text-anchor=\"middle\" x=\"727\" y=\"-57\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">requires_modification_of</text>\n</g>\n<!-- 225 -->\n<g id=\"node19\" class=\"node\">\n<title>225</title>\n<path fill=\"#e3f2fd\" stroke=\"black\" d=\"M921.5,-36C921.5,-36 764.5,-36 764.5,-36 758.5,-36 752.5,-30 752.5,-24 752.5,-24 752.5,-12 752.5,-12 752.5,-6 758.5,0 764.5,0 764.5,0 921.5,0 921.5,0 927.5,0 933.5,-6 933.5,-12 933.5,-12 933.5,-24 933.5,-24 933.5,-30 927.5,-36 921.5,-36\"/>\n<text text-anchor=\"middle\" x=\"843\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Type 2 Hypervisor (Hosted)</text>\n</g>\n<!-- 17&#45;&gt;225 -->\n<g id=\"edge32\" class=\"edge\">\n<title>17&#45;&gt;225</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M890.89,-82.99C898.75,-78.36 905.75,-72.47 911,-65 917.33,-55.98 913.64,-48.21 905.39,-41.76\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"907.01,-38.64 896.7,-36.21 903.24,-44.54 907.01,-38.64\"/>\n<text text-anchor=\"middle\" x=\"984.5\" y=\"-57\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">manages_hardware_access_for</text>\n</g>\n<!-- 41 -->\n<g id=\"node7\" class=\"node\">\n<title>41</title>\n<path fill=\"#e3f2fd\" stroke=\"black\" d=\"M1721,-534C1721,-534 1691,-534 1691,-534 1685,-534 1679,-528 1679,-522 1679,-522 1679,-510 1679,-510 1679,-504 1685,-498 1691,-498 1691,-498 1721,-498 1721,-498 1727,-498 1733,-504 1733,-510 1733,-510 1733,-522 1733,-522 1733,-528 1727,-534 1721,-534\"/>\n<text text-anchor=\"middle\" x=\"1706\" y=\"-512.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">AWS</text>\n</g>\n<!-- 41&#45;&gt;236 -->\n<g id=\"edge22\" class=\"edge\">\n<title>41&#45;&gt;236</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1691.59,-497.58C1686.34,-489.18 1682.28,-478.81 1685,-469 1685.82,-466.02 1686.98,-463.04 1688.32,-460.15\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1691.43,-461.77 1693.11,-451.31 1685.27,-458.44 1691.43,-461.77\"/>\n<text text-anchor=\"middle\" x=\"1696\" y=\"-472\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">uses</text>\n</g>\n<!-- 41&#45;&gt;236 -->\n<g id=\"edge39\" class=\"edge\">\n<title>41&#45;&gt;236</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1706.59,-497.91C1706.76,-492.22 1706.92,-485.84 1707,-480 1707.09,-474.01 1707.04,-467.58 1706.92,-461.49\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1710.41,-460.95 1706.66,-451.04 1703.41,-461.12 1710.41,-460.95\"/>\n<text text-anchor=\"middle\" x=\"1718\" y=\"-472\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">uses</text>\n</g>\n<!-- 57 -->\n<g id=\"node9\" class=\"node\">\n<title>57</title>\n<path fill=\"#e3f2fd\" stroke=\"black\" d=\"M1382.5,-368C1382.5,-368 1299.5,-368 1299.5,-368 1293.5,-368 1287.5,-362 1287.5,-356 1287.5,-356 1287.5,-344 1287.5,-344 1287.5,-338 1293.5,-332 1299.5,-332 1299.5,-332 1382.5,-332 1382.5,-332 1388.5,-332 1394.5,-338 1394.5,-344 1394.5,-344 1394.5,-356 1394.5,-356 1394.5,-362 1388.5,-368 1382.5,-368\"/>\n<text text-anchor=\"middle\" x=\"1341\" y=\"-346.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Dedicated EC2</text>\n</g>\n<!-- 57&#45;&gt;223 -->\n<g id=\"edge13\" class=\"edge\">\n<title>57&#45;&gt;223</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1339.21,-331.62C1338.85,-322.86 1339.25,-312.18 1342,-303 1342.9,-300 1344.13,-297.01 1345.55,-294.11\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1348.69,-295.68 1350.59,-285.26 1342.6,-292.22 1348.69,-295.68\"/>\n<text text-anchor=\"middle\" x=\"1363.5\" y=\"-306\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">bypasses</text>\n</g>\n<!-- 57&#45;&gt;223 -->\n<g id=\"edge41\" class=\"edge\">\n<title>57&#45;&gt;223</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1370.44,-331.71C1376.32,-326.79 1381.69,-320.86 1385,-314 1388.07,-307.62 1387.13,-300.7 1384.39,-294.21\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1387.26,-292.17 1379.36,-285.12 1381.14,-295.56 1387.26,-292.17\"/>\n<text text-anchor=\"middle\" x=\"1407.5\" y=\"-306\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">bypasses</text>\n</g>\n<!-- 67&#45;&gt;223 -->\n<g id=\"edge11\" class=\"edge\">\n<title>67&#45;&gt;223</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M2177.92,-187.07C2137.36,-190.71 2058.8,-199.87 1995,-220 1984.19,-223.41 1983,-228.29 1972,-231 1868.15,-256.61 1597.58,-239.89 1491,-249 1465.71,-251.16 1437.73,-254.77 1414.48,-258.11\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1413.89,-254.66 1404.5,-259.57 1414.9,-261.59 1413.89,-254.66\"/>\n<text text-anchor=\"middle\" x=\"2054\" y=\"-223\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">sends_commands_through</text>\n</g>\n<!-- 67&#45;&gt;223 -->\n<g id=\"edge42\" class=\"edge\">\n<title>67&#45;&gt;223</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M2177.71,-197.47C2163.89,-203.94 2146.91,-212.12 2132,-220 2123.37,-224.56 2122.39,-228.33 2113,-231 2046.49,-249.9 1559.91,-243.41 1491,-249 1465.79,-251.05 1437.93,-254.63 1414.74,-257.98\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1414.16,-254.52 1404.78,-259.44 1415.18,-261.45 1414.16,-254.52\"/>\n<text text-anchor=\"middle\" x=\"2191\" y=\"-223\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">sends_commands_through</text>\n</g>\n<!-- 95 -->\n<g id=\"node11\" class=\"node\">\n<title>95</title>\n<path fill=\"#e3f2fd\" stroke=\"black\" d=\"M226,-368C226,-368 156,-368 156,-368 150,-368 144,-362 144,-356 144,-356 144,-344 144,-344 144,-338 150,-332 156,-332 156,-332 226,-332 226,-332 232,-332 238,-338 238,-344 238,-344 238,-356 238,-356 238,-362 232,-368 226,-368\"/>\n<text text-anchor=\"middle\" x=\"191\" y=\"-346.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Virtualization</text>\n</g>\n<!-- 95&#45;&gt;222 -->\n<g id=\"edge17\" class=\"edge\">\n<title>95&#45;&gt;222</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M216.49,-331.96C232.4,-322.08 253.65,-310.2 274,-303 321.71,-286.12 378.85,-277.15 419.64,-272.53\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"420.07,-276.01 429.64,-271.45 419.32,-269.05 420.07,-276.01\"/>\n<text text-anchor=\"middle\" x=\"297.5\" y=\"-306\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">utilized_by</text>\n</g>\n<!-- 95&#45;&gt;222 -->\n<g id=\"edge48\" class=\"edge\">\n<title>95&#45;&gt;222</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M238.03,-336.71C262.77,-330.15 293.58,-321.84 321,-314 354.11,-304.54 391.08,-293.36 420.28,-284.39\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"421.33,-287.73 429.86,-281.44 419.28,-281.04 421.33,-287.73\"/>\n<text text-anchor=\"middle\" x=\"382.5\" y=\"-306\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">utilized_by</text>\n</g>\n<!-- 95&#45;&gt;17 -->\n<g id=\"edge38\" class=\"edge\">\n<title>95&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M169.17,-331.94C139.87,-306.89 94.19,-258.94 119,-220 165.9,-146.38 212.47,-158.76 297,-137 375.25,-116.86 598.25,-107.75 724.32,-104.11\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"724.45,-107.61 734.35,-103.82 724.25,-100.61 724.45,-107.61\"/>\n<text text-anchor=\"middle\" x=\"173\" y=\"-223\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">enables_virtualization_of</text>\n</g>\n<!-- 95&#45;&gt;117 -->\n<g id=\"edge49\" class=\"edge\">\n<title>95&#45;&gt;117</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M143.79,-348.63C87.23,-345.4 0,-330.31 0,-268 0,-268 0,-268 0,-100 0,-44 172.67,-26.7 275.1,-21.37\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"275.58,-24.85 285.39,-20.86 275.23,-17.86 275.58,-24.85\"/>\n<text text-anchor=\"middle\" x=\"24\" y=\"-181.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">has_model</text>\n</g>\n<!-- 114&#45;&gt;67 -->\n<g id=\"edge44\" class=\"edge\">\n<title>114&#45;&gt;67</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M1921.6,-346.69C2022.98,-341.27 2246.8,-325.01 2311,-285 2339.21,-267.42 2368.52,-246.15 2348,-220 2335.09,-203.55 2280.27,-193.83 2242.38,-188.96\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"2242.55,-185.45 2232.2,-187.71 2241.7,-192.4 2242.55,-185.45\"/>\n<text text-anchor=\"middle\" x=\"2366\" y=\"-264.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">moves</text>\n</g>\n<!-- 118&#45;&gt;223 -->\n<g id=\"edge10\" class=\"edge\">\n<title>118&#45;&gt;223</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M893.12,-185.33C1011.67,-186.73 1229.22,-193.03 1302,-220 1315.29,-224.93 1328.18,-233.63 1338.73,-242.15\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1336.76,-245.07 1346.65,-248.87 1341.29,-239.73 1336.76,-245.07\"/>\n<text text-anchor=\"middle\" x=\"1350\" y=\"-223\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">managed_by</text>\n</g>\n<!-- 118&#45;&gt;223 -->\n<g id=\"edge53\" class=\"edge\">\n<title>118&#45;&gt;223</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M893.02,-187.05C1044.99,-191.37 1364.55,-202.51 1381,-220 1386.25,-225.58 1385.71,-232.93 1382.79,-240.1\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1379.69,-238.48 1378.1,-248.95 1385.88,-241.76 1379.69,-238.48\"/>\n<text text-anchor=\"middle\" x=\"1412\" y=\"-223\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">managed_by</text>\n</g>\n<!-- 118&#45;&gt;17 -->\n<g id=\"edge37\" class=\"edge\">\n<title>118&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M814,-165.82C814,-155.19 814,-141.31 814,-129.2\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"817.5,-129.15 814,-119.15 810.5,-129.15 817.5,-129.15\"/>\n<text text-anchor=\"middle\" x=\"832.5\" y=\"-140\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">contains</text>\n</g>\n<!-- 274 -->\n<g id=\"node16\" class=\"node\">\n<title>274</title>\n<path fill=\"#e3f2fd\" stroke=\"black\" d=\"M2446,-368C2446,-368 2362,-368 2362,-368 2356,-368 2350,-362 2350,-356 2350,-356 2350,-344 2350,-344 2350,-338 2356,-332 2362,-332 2362,-332 2446,-332 2446,-332 2452,-332 2458,-338 2458,-344 2458,-344 2458,-356 2458,-356 2458,-362 2452,-368 2446,-368\"/>\n<text text-anchor=\"middle\" x=\"2404\" y=\"-346.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Compute Node</text>\n</g>\n<!-- 274&#45;&gt;223 -->\n<g id=\"edge9\" class=\"edge\">\n<title>274&#45;&gt;223</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M2349.85,-347.15C2168.74,-340.92 1593.22,-320.69 1554,-314 1537.51,-311.19 1534.17,-307.3 1518,-303 1483.72,-293.88 1444.76,-285.04 1414.6,-278.52\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1415.24,-275.08 1404.73,-276.41 1413.77,-281.93 1415.24,-275.08\"/>\n<text text-anchor=\"middle\" x=\"1565\" y=\"-306\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">uses</text>\n</g>\n<!-- 274&#45;&gt;223 -->\n<g id=\"edge59\" class=\"edge\">\n<title>274&#45;&gt;223</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M2349.87,-346.4C2208.44,-339.35 1816.24,-318.13 1491,-285 1465.75,-282.43 1437.77,-278.77 1414.52,-275.51\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"1414.92,-272.03 1404.53,-274.09 1413.94,-278.96 1414.92,-272.03\"/>\n<text text-anchor=\"middle\" x=\"1827\" y=\"-306\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">uses</text>\n</g>\n<!-- 274&#45;&gt;67 -->\n<g id=\"edge45\" class=\"edge\">\n<title>274&#45;&gt;67</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M2407.89,-331.8C2413,-304.35 2418.28,-250.61 2390,-220 2370.47,-198.86 2290.28,-190.25 2242.12,-186.92\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"2242.28,-183.43 2232.07,-186.28 2241.83,-190.41 2242.28,-183.43\"/>\n<text text-anchor=\"middle\" x=\"2461.5\" y=\"-264.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">manages_execution_of</text>\n</g>\n<!-- 274&#45;&gt;67 -->\n<g id=\"edge46\" class=\"edge\">\n<title>274&#45;&gt;67</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M2458.22,-347.25C2487.47,-343.7 2522.49,-334.89 2547,-314 2580.93,-285.08 2612.03,-252.95 2582,-220 2559.4,-195.2 2333.06,-187.7 2242.33,-185.67\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"2242.28,-182.17 2232.21,-185.46 2242.13,-189.17 2242.28,-182.17\"/>\n<text text-anchor=\"middle\" x=\"2667\" y=\"-264.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">manages_resource_allocation_for</text>\n</g>\n<!-- 227 -->\n<g id=\"node20\" class=\"node\">\n<title>227</title>\n<path fill=\"#e3f2fd\" stroke=\"black\" d=\"M2802,-285C2802,-285 2772,-285 2772,-285 2766,-285 2760,-279 2760,-273 2760,-273 2760,-261 2760,-261 2760,-255 2766,-249 2772,-249 2772,-249 2802,-249 2802,-249 2808,-249 2814,-255 2814,-261 2814,-261 2814,-273 2814,-273 2814,-279 2808,-285 2802,-285\"/>\n<text text-anchor=\"middle\" x=\"2787\" y=\"-263.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">KVM</text>\n</g>\n<!-- 274&#45;&gt;227 -->\n<g id=\"edge60\" class=\"edge\">\n<title>274&#45;&gt;227</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M2458.26,-342.82C2526.51,-334.14 2646.79,-315.86 2746,-285 2747.43,-284.56 2748.87,-284.08 2750.32,-283.59\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"2751.74,-286.79 2759.91,-280.05 2749.32,-280.23 2751.74,-286.79\"/>\n<text text-anchor=\"middle\" x=\"2683\" y=\"-306\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">uses</text>\n</g>\n<!-- 220 -->\n<g id=\"node17\" class=\"node\">\n<title>220</title>\n<path fill=\"#e3f2fd\" stroke=\"black\" d=\"M2290,-285C2290,-285 2108,-285 2108,-285 2102,-285 2096,-279 2096,-273 2096,-273 2096,-261 2096,-261 2096,-255 2102,-249 2108,-249 2108,-249 2290,-249 2290,-249 2296,-249 2302,-255 2302,-261 2302,-261 2302,-273 2302,-273 2302,-279 2296,-285 2290,-285\"/>\n<text text-anchor=\"middle\" x=\"2199\" y=\"-263.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Conceptual/Logical Architecture</text>\n</g>\n<!-- 220&#45;&gt;67 -->\n<g id=\"edge47\" class=\"edge\">\n<title>220&#45;&gt;67</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M2237.32,-248.82C2244.01,-244.04 2250.08,-238.14 2254,-231 2260.14,-219.81 2252.08,-209.78 2240.83,-201.96\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"2242.59,-198.93 2232.24,-196.68 2238.93,-204.9 2242.59,-198.93\"/>\n<text text-anchor=\"middle\" x=\"2300\" y=\"-223\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">defines_process_for</text>\n</g>\n<!-- 225&#45;&gt;17 -->\n<g id=\"edge35\" class=\"edge\">\n<title>225&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M803.03,-36.14C796.2,-40.91 790.03,-46.8 786,-54 782.21,-60.77 783.82,-67.98 787.73,-74.64\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"784.92,-76.73 793.67,-82.7 790.55,-72.58 784.92,-76.73\"/>\n<text text-anchor=\"middle\" x=\"803.5\" y=\"-57\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">runs_on</text>\n</g>\n<!-- 225&#45;&gt;17 -->\n<g id=\"edge36\" class=\"edge\">\n<title>225&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"#546e7a\" d=\"M836.86,-36.15C833.02,-46.89 827.98,-60.94 823.62,-73.13\"/>\n<polygon fill=\"#546e7a\" stroke=\"#546e7a\" points=\"820.23,-72.23 820.15,-82.82 826.82,-74.59 820.23,-72.23\"/>\n<text text-anchor=\"middle\" x=\"864.5\" y=\"-57\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">runs_on_top_of</text>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7ee639fe9790>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vanilla RAG Pipeline (Baseline)\n",
        "For comparison, this is our baseline Vanilla RAG. It performs the same initial vector search but does no graph traversal."
      ],
      "metadata": {
        "id": "E8C68tcselNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vanilla_rag(query_text: str, k: int, client, gemini_client) -> str:\n",
        "    \"\"\"\n",
        "    Performs a simple vanilla RAG retrieval.\n",
        "\n",
        "    It finds the top-k semantically similar entities (acting as documents)\n",
        "    based on the query and formats their properties into a single context string.\n",
        "    This function does NOT perform any graph traversal.\n",
        "    \"\"\"\n",
        "    # Retrieve the top K most relevant entities based on semantic similarity.\n",
        "    top_entities = find_semantic_entry_points(query_text, k, client, gemini_client)\n",
        "\n",
        "    # ormat the retrieved entities into a single context string.\n",
        "    context_strings = []\n",
        "    for entity in top_entities:\n",
        "        context_strings.append(_format_entity_properties(entity))\n",
        "\n",
        "    return \"\\n\\n\".join(context_strings)\n"
      ],
      "metadata": {
        "id": "Q_PEmhp0Dia6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We run the Vanilla RAG pipeline, retrieving 20 documents to match the context size of our Graph RAG test."
      ],
      "metadata": {
        "id": "dnSgpD9GeraM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What does a hypervisor do?\"\n",
        "k_documents = 20 # The number of top documents (entities) to retrieve. Here k is equivalent to the max_entities parameter in graph RAG above\n",
        "\n",
        "vanilla_rag_context = vanilla_rag(\n",
        "    query_text=query,\n",
        "    k=k_documents,\n",
        "    client=client,\n",
        "    gemini_client=gemini_client\n",
        ")\n",
        "\n",
        "print(\"--- Generated Vanilla RAG Context ---\")\n",
        "print(vanilla_rag_context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MPr0-q8yYDNc",
        "outputId": "e1dc6209-7e5f-4572-fa92-33f64f40c1a7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Generated Vanilla RAG Context ---\n",
            "Entity: 'Hypervisor' (Class: 'Hypervisor', ID: 223)\n",
            "  - definition: a software layer that allows multiple virtual machines (VMs) to run on a single physical machine by abstracting hardware resources.\n",
            "  - key_feature: VM Process Isolation (Kernel-Level), Device Mediation & Access Control, Direct Execution of Commands from VMs\n",
            "  - responsibility: Process Isolation, Resource Management, Virtual Machine Execution, Hardware Access Control\n",
            "\n",
            "Entity: 'hypervisors' (Class: 'Hypervisor', ID: 222)\n",
            "  - responsibility: create and manage virtual machines.\n",
            "\n",
            "Entity: 'Hypervisors' (Class: 'Hypervisor', ID: 236)\n",
            "  - responsibility: manage VM isolation\n",
            "  - security_aspect: manage VM isolation\n",
            "\n",
            "Entity: 'System-Level Virtualization' (Class: 'Virtualization Technology', ID: 107)\n",
            "  - definition: Allows multiple operating systems to run on a single hardware system.\n",
            "  - example: VirtualBox, VMware Workstation\n",
            "  - type: System-Level Virtualization\n",
            "\n",
            "Entity: 'Type 2 Hypervisor (Hosted)' (Class: 'Hypervisor', ID: 225)\n",
            "  - definition: Runs on top of an existing OS.\n",
            "  - example: VirtualBox, VMware Workstation\n",
            "  - type: Type 2 Hypervisor\n",
            "  - usage_context: Less scalable but easier to deploy.\n",
            "\n",
            "Entity: 'Type 1 Hypervisor' (Class: 'Hypervisor', ID: 231)\n",
            "  - definition: Runs directly on the physical hardware without an underlying OS.\n",
            "  - key_feature: More efficient, secure, and scalable.\n",
            "  - lifecycle_management_capability: High scalability, Support for live migration and snapshots.\n",
            "  - platform_management_aspect: execute commands directly.\n",
            "  - security_aspect: more secure since they run directly on hardware.\n",
            "  - type: Type 1\n",
            "  - usage_context: Large-scale cloud environments.\n",
            "\n",
            "Entity: 'Type 2 Hypervisor' (Class: 'Hypervisor', ID: 232)\n",
            "  - definition: Runs on top of an existing OS, which manages hardware access.\n",
            "  - key_feature: Less efficient and secure due to OS dependency.\n",
            "  - lifecycle_management_capability: Support for live migration and snapshots.\n",
            "  - platform_management_aspect: depend on the base OS for execution.\n",
            "  - security_aspect: introduce additional risk due to dependency on the host OS; Security vulnerabilities due to OS dependency.\n",
            "  - type: Type 2\n",
            "  - usage_context: Testing and development environments.\n",
            "\n",
            "Entity: 'Type 1 Hypervisor (Bare Metal)' (Class: 'Hypervisor', ID: 224)\n",
            "  - definition: Runs directly on hardware.\n",
            "  - example: VMware ESXi, KVM, Xen\n",
            "  - type: Type 1 Hypervisor\n",
            "  - usage_context: Highly scalable and efficient\n",
            "\n",
            "Entity: 'KVM (Kernel-based Virtual Machine)' (Class: 'Hypervisor', ID: 233)\n",
            "  - definition: Open-source Linux hypervisor.\n",
            "  - key_feature: Allows direct access to hardware.\n",
            "  - type: Type 1\n",
            "  - usage_context: Default hypervisor in Linux-based cloud environments.\n",
            "\n",
            "Entity: 'Xen' (Class: 'Hypervisor', ID: 228)\n",
            "  - type: Type 1 Hypervisor\n",
            "\n",
            "Entity: 'AWS Nitro Hypervisor' (Class: 'Hypervisor', ID: 235)\n",
            "  - definition: is based on Xen.\n",
            "\n",
            "Entity: 'Xen Hypervisor' (Class: 'Hypervisor', ID: 234)\n",
            "  - type: Type 1\n",
            "  - usage_context: Used by AWS (with modifications), Used in ARM processors for mobile and embedded systems.\n",
            "  - virtualization_model_support: Supports both para-virtualization and full virtualization.\n",
            "\n",
            "Entity: 'Server/Machine Virtualization' (Class: 'Virtualization Technology', ID: 96)\n",
            "  - definition: Enables multiple VMs to run on a single physical machine.\n",
            "  - purpose: Abstracts hardware resources.\n",
            "  - type: Server/Machine Virtualization\n",
            "\n",
            "Entity: 'KVM Hypervisor' (Class: 'Hypervisor', ID: 237)\n",
            "  - usage_context: Default hypervisor used in OpenStack.\n",
            "\n",
            "Entity: 'Full Virtualization' (Class: 'Virtualization Technology', ID: 116)\n",
            "  - approach: Hypervisor exposes the same hardware interface to the virtual machine as it does in physical hardware.\n",
            "  - benefit: OS inside VM does not need modification.\n",
            "  - resource_optimization: Higher overhead due to full emulation.\n",
            "  - type: Full Virtualization\n",
            "\n",
            "Entity: 'KVM' (Class: 'Hypervisor', ID: 227)\n",
            "  - type: Type 1 Hypervisor\n",
            "  - usage_context: default\n",
            "\n",
            "Entity: 'I/O Virtualization' (Class: 'Virtualization Technology', ID: 98)\n",
            "  - definition: Virtualizes input/output devices like storage, network interfaces, and disk controllers.\n",
            "  - type: I/O Virtualization\n",
            "\n",
            "Entity: 'VirtualBox' (Class: 'Hypervisor', ID: 229)\n",
            "  - type: Type 2\n",
            "\n",
            "Entity: 'Virtualization' (Class: 'Virtualization Technology', ID: 95)\n",
            "  - approach: Multiplexing, Aggregation, Emulation\n",
            "  - benefit: Optimizes computing power, storage, and network resources; enables easy migration of virtual machines; allows multiple applications on a single physical resource; reduces the need for physical hardware.\n",
            "  - cloud_computing_enabler: Most cloud computing infrastructures rely on virtualization since it is a common characteristic that helps achieve essential cloud features.\n",
            "  - cost_saving: Reduces the need for physical hardware.\n",
            "  - definition: allows multiple applications to run on a single physical resource.\n",
            "  - flexibility: Virtualization allows multiple applications to run on a single physical resource.\n",
            "  - implementation_level: Server/Machine Virtualization, Network Virtualization, I/O Virtualization\n",
            "  - migration_ease: Virtual machines (VMs) can be migrated easily compared to physical machines.\n",
            "  - purpose: Optimizes computing power, storage, and network resources.\n",
            "  - resource_optimization: Optimizes computing power, storage, and network resources.\n",
            "  - type: Hardware-Level Virtualization, System-Level Virtualization, Application-Level Virtualization, Nested Virtualization, Memory Virtualization\n",
            "\n",
            "Entity: 'VMware Workstation' (Class: 'Hypervisor', ID: 230)\n",
            "  - type: Type 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The resulting context and the query is similarly passed to the gemini-2.5-flash to generate the response."
      ],
      "metadata": {
        "id": "B7bNL-xWeuLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = gemini_client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=f\"Use the given context to answer the user's query. \\nQuery: {query}, \\nRetrieved Contex: {vanilla_rag_context}\"\n",
        ")\n",
        "\n",
        "answer = (response.text)\n",
        "\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ewsaxZmMYYL4",
        "outputId": "f54827f3-a85a-480b-d7aa-abe93d13b0ee"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A hypervisor is a software layer that allows multiple virtual machines (VMs) to run on a single physical machine by abstracting hardware resources.\n",
            "\n",
            "Its primary functions and responsibilities include:\n",
            "*   Creating and managing virtual machines.\n",
            "*   Enabling multiple operating systems to run on a single hardware system.\n",
            "*   Providing VM Process Isolation (managing VM isolation at the kernel level).\n",
            "*   Managing resources for the virtual machines.\n",
            "*   Controlling hardware access for the virtual machines.\n",
            "*   Facilitating Device Mediation & Access Control.\n",
            "*   Enabling the direct execution of commands from virtual machines.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I asked two separate reasoning LLMs, GPT-o3 and Gemini 2.5 Pro, to evaluate which response is better. I gave the query, response 1 (Graph RAG) and response 2 (Vanilla RAG)."
      ],
      "metadata": {
        "id": "vi6LVfJje5vc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT o3"
      ],
      "metadata": {
        "id": "UdyTDDrebG_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Response 1 is the stronger answer.**\n",
        "\n",
        "| Criterion                         | Response 1                                                                                          | Response 2                                                                                                                                                                                                          | Why Response 1 Wins                                            |\n",
        "| --------------------------------- | --------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------- |\n",
        "| **Accuracy**                      | Uses standard, widely-accepted terms: *resource management, VM isolation, hardware access control.* | Introduces fuzzy or misleading phrases such as “VM Process Isolation (…at the kernel level)” and “direct execution of commands,” which do not cleanly map to how modern hypervisors expose privileged instructions. | Avoids potentially confusing or technically imprecise wording. |\n",
        "| **Completeness (core duties)**    | Lists every fundamental hypervisor responsibility most introductory texts highlight.                | Adds two extra bullets (“multiple OS on one system,” “device mediation”), but both are simply restatements or sub-cases of points already covered.                                                                  | Provides all essentials without padding.                       |\n",
        "| **Clarity & Redundancy**          | Five distinct, non-overlapping bullets.                                                             | Duplicates ideas: “Creating and managing VMs” + “Enabling multiple operating systems…,” and again re-states isolation.                                                                                              | Tighter structure helps the reader grasp each point instantly. |\n",
        "| **Conciseness / Signal-to-Noise** | Brief, direct, no repetition.                                                                       | Longer, with repeated concepts and an extra heading line that adds no new information.                                                                                                                              | Better signal-to-noise ratio.                                  |\n",
        "| **Writing quality**               | Parallel bullet syntax, consistent verb choice, no awkward capitalization.                          | Similar style, but some bullets start with gerunds, others with nouns, and capitalization is inconsistent.                                                                                                          | More polished and professional.                                |\n",
        "\n",
        "In short, Response 1 delivers the same substantive information in a clearer, more precise, and non-redundant manner—hallmarks of higher-quality technical writing.\n"
      ],
      "metadata": {
        "id": "Sj2jgjkXJByQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemini-2.5-pro"
      ],
      "metadata": {
        "id": "wTG1SCxYbLaw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Response 1 is better.\n",
        "\n",
        "It's more concise and clearly organized. The bullet points use **bolded** keywords to define distinct functions, making the information easier to scan and understand. Each point is a clear, separate function (Creation, Management, Execution, Control, Isolation), whereas Response 2 has some overlap and less direct points (e.g., \"Enabling multiple operating systems...\" is a result of what a hypervisor does, not a core function itself)."
      ],
      "metadata": {
        "id": "QTMymM_XJSHK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EVALS"
      ],
      "metadata": {
        "id": "LPPT4hYxyPDg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Part 1: Numerical Metrics\n",
        "\n",
        "We'll first evaluate the two methods using standard retrieval metrics:\n",
        "\n",
        "* **Precision@k:** Measures the fraction of retrieved items that are relevant.\n",
        "\n",
        "$$\n",
        "\\text{Precision@k} = \\frac{\\left| \\text{Retrieved} \\cap \\text{Golden} \\right|}\n",
        "                           {\\left| \\text{Retrieved} \\right|}\n",
        "$$\n",
        "\n",
        "* **Recall@k:** Measures the fraction of relevant items that were successfully retrieved.\n",
        "\n",
        "$$\n",
        "\\text{Recall@k} = \\frac{\\left| \\text{Retrieved} \\cap \\text{Golden} \\right|}\n",
        "                       {\\left| \\text{Golden} \\right|}\n",
        "$$\n",
        "\n",
        "* **Mean Average Precision (MAP):** The mean of Average Precision (AP) scores across all queries.  \n",
        "  AP rewards ranking relevant items higher in the list.\n",
        "\n",
        "$$\n",
        "\\text{AP} = \\frac{\\displaystyle \\sum_{k=1}^{n}\n",
        "                 \\bigl(P(k)\\,\\times\\,\\text{rel}(k)\\bigr)}\n",
        "                 {\\text{Number of relevant documents}}\n",
        "$$\n",
        "\n",
        "where $P(k)$ is the precision at cut-off $k$ and $\\text{rel}(k)$ is 1 if the item at rank $k$ is relevant, 0 otherwise."
      ],
      "metadata": {
        "id": "ZWRJQyWgfSNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Set\n",
        "We use a predefined set of 10 queries and a corresponding \"golden set\" of ideal entity IDs for each.\n",
        "\n",
        "Note that we need the returned entities' entity ids from each RAG method to compute our evaluaion metrics."
      ],
      "metadata": {
        "id": "m4NEGwrylJvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_queries = [\n",
        "  \"How can AWS IAM policies be used to manage user access and permissions within a specific Virtual Private Cloud (VPC)?\",\n",
        "  \"Compare the specific functions of the L3 Agent and the DHCP Agent within an OpenStack Networking Node.\",\n",
        "  \"Explain the full lifecycle: How do Cloud-Native Applications, built on a Microservices Architecture, get deployed as Containers and then managed by an orchestration platform like Kubernetes?\",\n",
        "  \"Why is para-virtualization, as used by the Xen hypervisor, considered to have lower overhead compared to the full virtualization approach?\",\n",
        "  \"What is the primary use case for attaching an EBS volume, a type of block storage, to an AWS EC2 instance for persistent storage?\",\n",
        "  \"Describe the process of a VM launch in OpenStack, detailing the roles of the Image Service, Compute Service, and the underlying KVM hypervisor.\",\n",
        "  \"Compare the security characteristics and control levels of a Public Cloud versus a Private Cloud deployment model.\",\n",
        "  \"How does a Multicloud strategy help an organization avoid vendor lock-in, and which cloud service providers are major players in this ecosystem?\",\n",
        "  \"What role does middleware for 'Provisioning & Configuration' play in enabling the 'On-Demand Self-Service' characteristic of cloud computing?\",\n",
        "  \"Explain how Open vSwitch enables software-defined networking within OpenStack by connecting virtual machines on Compute and Network nodes.\"\n",
        "]"
      ],
      "metadata": {
        "id": "N8UurTTUzmPD"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "golden_ids = {\n",
        "    \"0\": [243, 156, 170, 174, 175, 159, 160, 173, 162, 161, 164, 169, 171, 172, 48],\n",
        "    \"1\": [182, 183, 271, 275, 180, 257, 164, 161, 187, 188, 189, 256, 274, 267, 20],\n",
        "    \"2\": [208, 209, 238, 239, 240, 121, 127, 124, 125, 128, 129, 130, 131, 132, 122],\n",
        "    \"3\": [117, 116, 228, 234, 224, 223, 222, 231, 225, 232, 106, 95, 118, 114, 233],\n",
        "    \"4\": [200, 199, 203, 52, 61, 48, 190, 194, 193, 196, 205, 206, 75, 70, 197],\n",
        "    \"5\": [260, 256, 237, 227, 274, 273, 269, 270, 254, 265, 264, 259, 261, 20, 266],\n",
        "    \"6\": [86, 84, 92, 87, 83, 38, 36, 89, 30, 32, 33, 34, 48, 41, 42],\n",
        "    \"7\": [90, 91, 41, 42, 43, 44, 45, 46, 48, 140, 142, 144, 145, 149, 89],\n",
        "    \"8\": [23, 73, 21, 244, 245, 122, 261, 241, 242, 80, 75, 137, 24, 25, 140],\n",
        "    \"9\": [180, 111, 97, 20, 270, 275, 271, 188, 181, 267, 257, 182, 183, 174, 274]\n",
        "}"
      ],
      "metadata": {
        "id": "_DjE6XCZzqce"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function to retrieve entity ids of entities fetched and traversed using the above-defined graph RAG function."
      ],
      "metadata": {
        "id": "9mm73Oo8fWrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_graph_rag_ids(query_text: str, k: int, max_hops: int, max_entities: int, client, gemini_client) -> List[int]:\n",
        "    \"\"\"\n",
        "    Runs the Graph RAG process to retrieve only the entity IDs.\n",
        "\n",
        "    \"\"\"\n",
        "    # We call the modified graph_rag function to get the structured data\n",
        "    _, retrieved_entities_dict, _ = graph_rag(\n",
        "        query_text=query_text,\n",
        "        k=k,\n",
        "        max_hops=max_hops,\n",
        "        max_entities=max_entities,\n",
        "        client=client,\n",
        "        gemini_client=gemini_client\n",
        "    )\n",
        "    # The keys of the entities dictionary are the unique entity IDs collected\n",
        "    retrieved_ids = list(retrieved_entities_dict.keys())\n",
        "    print(\"\\nGraph RAG ids: \", retrieved_ids)\n",
        "    return retrieved_ids"
      ],
      "metadata": {
        "id": "PkGVMFPhZenx"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function to retrieve entity ids of entities fetched using the above-defined vanilla RAG function."
      ],
      "metadata": {
        "id": "wHVoc_8Kf1bV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_vanilla_rag_ids(query_text: str, k: int, client, gemini_client) -> List[int]:\n",
        "    \"\"\"\n",
        "    Runs the core logic of Vanilla RAG to retrieve only the entity IDs.\n",
        "\n",
        "    \"\"\"\n",
        "    # find_semantic_entry_points returns a list of entity dictionaries\n",
        "    retrieved_entities = find_semantic_entry_points(query_text, k, client, gemini_client)\n",
        "    # Extract just the 'id' from each dictionary\n",
        "    retrieved_ids = [entity.get('id') for entity in retrieved_entities if entity.get('id') is not None]\n",
        "    print(\"\\nVanilla RAG ids: \", retrieved_ids)\n",
        "    return retrieved_ids"
      ],
      "metadata": {
        "id": "OlILomaWyXPL"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper functions to calculate vector search metrics."
      ],
      "metadata": {
        "id": "ip-2lnc_f4bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_precision(retrieved: List[int], golden: List[int]) -> float:\n",
        "    \"\"\"Calculates precision: |retrieved & golden| / |retrieved|\"\"\"\n",
        "    if not retrieved:\n",
        "        return 0.0\n",
        "\n",
        "    retrieved_set = set(retrieved)\n",
        "    golden_set = set(golden)\n",
        "    intersection = retrieved_set.intersection(golden_set)\n",
        "\n",
        "    return len(intersection) / len(retrieved_set)\n",
        "\n",
        "def calculate_recall(retrieved: List[int], golden: List[int]) -> float:\n",
        "    \"\"\"Calculates recall: |retrieved & golden| / |golden|\"\"\"\n",
        "    if not golden:\n",
        "        return 0.0\n",
        "\n",
        "    retrieved_set = set(retrieved)\n",
        "    golden_set = set(golden)\n",
        "    intersection = retrieved_set.intersection(golden_set)\n",
        "\n",
        "    return len(intersection) / len(golden_set)\n",
        "\n",
        "def calculate_average_precision(retrieved: List[int], golden: List[int]) -> float:\n",
        "    \"\"\"Calculates Mean Average Precision (MAP), which rewards correct ranking.\"\"\"\n",
        "    if not golden:\n",
        "        return 0.0\n",
        "\n",
        "    golden_set = set(golden)\n",
        "    hits = 0\n",
        "    sum_of_precisions = 0.0\n",
        "\n",
        "    for i, p in enumerate(retrieved):\n",
        "        if p in golden_set:\n",
        "            hits += 1\n",
        "            sum_of_precisions += hits / (i + 1)\n",
        "\n",
        "    return sum_of_precisions / len(golden_set)"
      ],
      "metadata": {
        "id": "8dVXAaZ7yc8g"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets define a function to run our evauation. We use k = 15. This the max amount of entities to be used for evauation. This is the same as the amount of golden ids for each query in the svaluation set.\n",
        "The initial k for graoh RAG is set as 5 so 1/3 entities for graph RAG are through vector search and the remaining 2/3 are fetched via graph traversal with max hops configured to 2."
      ],
      "metadata": {
        "id": "YRUwQziHgFEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_evaluation(eval_queries: List[str], golden_ids: Dict[str, List[int]], client, gemini_client):\n",
        "    \"\"\"\n",
        "    Orchestrates the evaluation process for both Vanilla and Graph RAG.\n",
        "    \"\"\"\n",
        "    vanilla_results = {}\n",
        "    graph_results = {}\n",
        "\n",
        "    # Define evaluation parameters\n",
        "    RETRIEVAL_BUDGET = 15 # this is the k for vanilla RAG and max_entities for graph RAG\n",
        "    GRAPH_RAG_K_INITIAL = 5\n",
        "    GRAPH_RAG_MAX_HOPS = 2\n",
        "\n",
        "    for i, query in enumerate(tqdm(eval_queries, desc=\"Evaluating Queries\")):\n",
        "        query_id = str(i)\n",
        "        golden_set = golden_ids[query_id]\n",
        "\n",
        "        # Evaluate Vanilla RAG\n",
        "        vanilla_retrieved = retrieve_vanilla_rag_ids(query, RETRIEVAL_BUDGET, client, gemini_client)\n",
        "        vanilla_results[query_id] = {\n",
        "            'precision': calculate_precision(vanilla_retrieved, golden_set),\n",
        "            'recall': calculate_recall(vanilla_retrieved, golden_set),\n",
        "            'average_precision': calculate_average_precision(vanilla_retrieved, golden_set)\n",
        "        }\n",
        "\n",
        "        # Evaluate Graph RAG\n",
        "        graph_retrieved = retrieve_graph_rag_ids(\n",
        "            query,\n",
        "            k=GRAPH_RAG_K_INITIAL,\n",
        "            max_hops=GRAPH_RAG_MAX_HOPS,\n",
        "            max_entities=RETRIEVAL_BUDGET,\n",
        "            client=client,\n",
        "            gemini_client=gemini_client\n",
        "        )\n",
        "        graph_results[query_id] = {\n",
        "            'precision': calculate_precision(graph_retrieved, golden_set),\n",
        "            'recall': calculate_recall(graph_retrieved, golden_set),\n",
        "            'average_precision': calculate_average_precision(graph_retrieved, golden_set)\n",
        "        }\n",
        "\n",
        "    return vanilla_results, graph_results"
      ],
      "metadata": {
        "id": "YGzRNwJjy1Du"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper function to display the evaluation results."
      ],
      "metadata": {
        "id": "S-6wjbE0gofK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_evaluation_results(vanilla_results: dict, graph_results: dict):\n",
        "    \"\"\"Calculates and prints the mean of the metrics in a formatted table.\"\"\"\n",
        "\n",
        "    def calculate_means(results: dict):\n",
        "        num_queries = len(results)\n",
        "        if num_queries == 0:\n",
        "            return {'precision': 0, 'recall': 0, 'map': 0}\n",
        "\n",
        "        mean_p = sum(res['precision'] for res in results.values()) / num_queries\n",
        "        mean_r = sum(res['recall'] for res in results.values()) / num_queries\n",
        "        mean_ap = sum(res['average_precision'] for res in results.values()) / num_queries\n",
        "\n",
        "        return {'precision': mean_p, 'recall': mean_r, 'map': mean_ap}\n",
        "\n",
        "    vanilla_means = calculate_means(vanilla_results)\n",
        "    graph_means = calculate_means(graph_results)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"           Retrieval Evaluation Summary\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"{'Metric':<20} | {'Vanilla RAG':<15} | {'Graph RAG':<15}\")\n",
        "    print(\"-\"*50)\n",
        "    print(f\"{'Precision':<20} | {vanilla_means['precision']:<15.4f} | {graph_means['precision']:<15.4f}\")\n",
        "    print(f\"{'Recall':<20} | {vanilla_means['recall']:<15.4f} | {graph_means['recall']:<15.4f}\")\n",
        "    print(f\"{'MAP (Rank-Aware)':<20} | {vanilla_means['map']:<15.4f} | {graph_means['map']:<15.4f}\")\n",
        "    print(\"=\"*50)"
      ],
      "metadata": {
        "id": "lrr2d9Z1zSYf"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets run our evals."
      ],
      "metadata": {
        "id": "zplLR4xOgsko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vanilla_results, graph_results = run_evaluation(eval_queries, golden_ids, client, gemini_client)\n",
        "display_evaluation_results(vanilla_results, graph_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Izdm4uASzhSy",
        "outputId": "28091054-890c-439f-dc7a-31ec1eb53e3b"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Queries:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vanilla RAG ids:  [156, 160, 159, 170, 243, 173, 149, 169, 168, 216, 161, 162, 174, 80, 165]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Queries:  10%|█         | 1/10 [00:00<00:05,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Graph RAG ids:  [156, 160, 159, 170, 243, 141, 149, 161, 171, 172, 10, 41, 67, 80, 118]\n",
            "\n",
            "Vanilla RAG ids:  [271, 183, 182, 20, 164, 275, 181, 257, 267, 268, 161, 188, 180, 162, 273]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Queries:  20%|██        | 2/10 [00:01<00:04,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Graph RAG ids:  [271, 183, 182, 20, 164, 219, 237, 240, 255, 256, 258, 259, 264, 265, 266]\n",
            "\n",
            "Vanilla RAG ids:  [121, 208, 127, 137, 209, 131, 132, 238, 129, 125, 76, 122, 138, 124, 134]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Queries:  30%|███       | 3/10 [00:01<00:03,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Graph RAG ids:  [121, 208, 127, 137, 209, 210, 211, 212, 238, 240, 3, 13, 27, 32, 76]\n",
            "\n",
            "Vanilla RAG ids:  [116, 117, 234, 95, 228, 96, 232, 224, 233, 107, 223, 231, 225, 106, 238]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Queries:  40%|████      | 4/10 [00:01<00:02,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Graph RAG ids:  [116, 117, 234, 95, 228, 222, 223, 224, 235, 152, 3, 9, 17, 19, 35]\n",
            "\n",
            "Vanilla RAG ids:  [199, 200, 194, 192, 52, 197, 193, 48, 41, 191, 170, 203, 55, 165, 201]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Queries:  50%|█████     | 5/10 [00:02<00:02,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Graph RAG ids:  [199, 200, 194, 192, 52, 17, 41, 60, 65, 66, 79, 191, 193, 195, 196]\n",
            "\n",
            "Vanilla RAG ids:  [256, 260, 20, 237, 274, 270, 80, 223, 69, 233, 75, 67, 259, 220, 227]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Queries:  60%|██████    | 6/10 [00:02<00:01,  2.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Graph RAG ids:  [256, 260, 20, 237, 274, 219, 223, 227, 240, 255, 258, 259, 262, 264, 265]\n",
            "\n",
            "Vanilla RAG ids:  [87, 86, 92, 83, 84, 32, 30, 85, 160, 93, 89, 48, 34, 36, 75]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Queries:  70%|███████   | 7/10 [00:03<00:01,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Graph RAG ids:  [87, 86, 92, 83, 84, 139, 41, 42, 43, 44, 45, 46, 47, 85, 89]\n",
            "\n",
            "Vanilla RAG ids:  [90, 42, 44, 254, 142, 41, 43, 48, 45, 91, 46, 143, 49, 30, 95]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Queries:  80%|████████  | 8/10 [00:03<00:00,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Graph RAG ids:  [90, 42, 44, 254, 142, 144, 3, 9, 32, 36, 37, 38, 74, 84, 85]\n",
            "\n",
            "Vanilla RAG ids:  [23, 73, 72, 3, 4, 26, 21, 52, 30, 77, 41, 75, 79, 78, 71]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating Queries:  90%|█████████ | 9/10 [00:04<00:00,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Graph RAG ids:  [23, 73, 72, 3, 4, 209, 207, 264, 140, 141, 142, 143, 146, 150, 1]\n",
            "\n",
            "Vanilla RAG ids:  [180, 20, 270, 271, 276, 275, 97, 274, 256, 257, 181, 188, 219, 182, 254]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Queries: 100%|██████████| 10/10 [00:04<00:00,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Graph RAG ids:  [180, 20, 270, 271, 276, 219, 221, 237, 240, 255, 256, 257, 258, 259, 264]\n",
            "\n",
            "==================================================\n",
            "           Retrieval Evaluation Summary\n",
            "==================================================\n",
            "Metric               | Vanilla RAG     | Graph RAG      \n",
            "--------------------------------------------------\n",
            "Precision            | 0.6400          | 0.4267         \n",
            "Recall               | 0.6400          | 0.4267         \n",
            "MAP (Rank-Aware)     | 0.5726          | 0.3775         \n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results show that **Vanilla RAG scores higher** on these metrics.\n",
        "\n",
        "This is because these metrics measure simple ID overlap. Vanilla RAG's strategy is 100% optimized for this (retrieving the top 15 most similar items through pure vector search), while Graph RAG's strategy involves exploring structurally-related nodes that may be less semantically similar, thus lowering its overlap score. This highlights the limitations of using these metrics alone to judge the *utility* of a retrieved context.\n",
        "These metrics also do not reflect the cost and speed optimisation provided by graph traversal over vector search."
      ],
      "metadata": {
        "id": "8AtSUsZNgva6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Part 2: LLM-as-a-Judge"
      ],
      "metadata": {
        "id": "YXaJxALJRW1E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the limitations of numerical metrics, we'll use a more qualitative approach. An LLM-as-a-Judge will evaluate the **quality of the final generated answer** from each RAG method. This better reflects the true performance of the system.\n",
        "\n",
        "**The Process:**\n",
        "1.  Generate an answer using the Vanilla RAG context.\n",
        "2.  Generate an answer using the Graph RAG context.\n",
        "3.  Have a powerful reasoning LLM act as a judge and vote for the better answer.\n",
        "\n",
        "For the answer generation, we use [`gemini-2.5-flash`](https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash), whereas [`gemini-2.5-pro`](https://ai.google.dev/gemini-api/docs/models#gemini-2.5-pro) is best-suited to be the judge.\n",
        "\n",
        "For the answer generation, the LLM is simple provided the query + the retrieved context and is prompted to generate the answer based solely on that context.\n",
        "\n",
        "The judge LLM is instructed to only respond with the choice 1 (for vanilla RAG response preference) or 2 (for graph RAG response preference)."
      ],
      "metadata": {
        "id": "s-aGvKm4hIpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(query: str, context: str, generator_client) -> str:\n",
        "    \"\"\"\n",
        "    Generates an answer to a query using the provided context.\n",
        "    Uses the gemini-2.5-flash model for speed and efficiency.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        \"Based only on the provided context, answer the following query concisely. \"\n",
        "        \"If the context does not contain the answer, state that you cannot answer based on the information given.\\n\\n\"\n",
        "        f\"Query: {query}\\n\\n\"\n",
        "        f\"Context:\\n{context}\\n\\n\"\n",
        "        \"Answer:\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        # Use the gemini_client already initialized\n",
        "        response = generator_client.models.generate_content(\n",
        "            model=\"gemini-2.5-flash\",\n",
        "            contents=prompt\n",
        "        )\n",
        "        print(response.text)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during answer generation: {e}\")\n",
        "        return \"Error: Could not generate an answer.\"\n",
        "\n",
        "def judge_answers(query: str, answer_1: str, answer_2: str, judge_client) -> int:\n",
        "    \"\"\"\n",
        "    Asks a powerful LLM judge to decide which of two answers is better.\n",
        "    Uses gemini-2.5-pro for its strong reasoning capabilities.\n",
        "    Returns 1 for Answer 1 or 2 for Answer 2.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        \"You are an impartial judge. Your task is to evaluate two AI-generated answers to a user's query and determine which is better. \"\n",
        "        \"Consider correctness, completeness, and clarity.\\n\\n\"\n",
        "        f\"USER QUERY:\\n'{query}'\\n\\n\"\n",
        "        \"--- ANSWER 1 ---\\n\"\n",
        "        f\"{answer_1}\\n\\n\"\n",
        "        \"--- ANSWER 2 ---\\n\"\n",
        "        f\"{answer_2}\\n\\n\"\n",
        "        \"--- INSTRUCTIONS ---\\n\"\n",
        "        \"Output only the number of the better answer: '1' or '2'.\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        # Use the gemini_client for the judge model\n",
        "        response = judge_client.models.generate_content(\n",
        "            model=\"gemini-2.5-pro\",\n",
        "            contents=prompt\n",
        "        )\n",
        "\n",
        "        # Parse the last line of the response to get the deterministic vote\n",
        "        last_line = response.text.strip().split('\\n')[-1].strip()\n",
        "        if last_line == \"1\":\n",
        "            return 1\n",
        "        elif last_line == \"2\":\n",
        "            return 2\n",
        "        else:\n",
        "            # If the model fails to follow instructions, default to 0.\n",
        "            return 0\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during judging: {e}\")\n",
        "        return 0 # Return 0 for error"
      ],
      "metadata": {
        "id": "DNpss89VRuMc"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define the orchestration function to run the LLM-as-a-Judge evals."
      ],
      "metadata": {
        "id": "5iMkrWVqht_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_llm_as_judge_evaluation(eval_queries: List[str], client, gemini_client):\n",
        "    \"\"\"\n",
        "    Orchestrates the end-to-end evaluation using an LLM-as-a-Judge.\n",
        "    \"\"\"\n",
        "    scores = {\"vanilla_wins\": 0, \"graph_wins\": 0, \"errors\": 0}\n",
        "\n",
        "    # Define RAG parameters for this evaluation ---\n",
        "    VANILLA_K = 15\n",
        "    GRAPH_K_INITIAL = 5\n",
        "    GRAPH_MAX_HOPS = 2\n",
        "    GRAPH_MAX_ENTITIES = 15\n",
        "\n",
        "    print(\"--- Starting LLM-as-a-Judge Evaluation ---\")\n",
        "\n",
        "    for query in tqdm(eval_queries, desc=\"Judging Queries\"):\n",
        "        # Get contexts from both RAG methods\n",
        "        vanilla_context = vanilla_rag(query, VANILLA_K, client, gemini_client)\n",
        "        graph_context, _, _ = graph_rag(\n",
        "            query, GRAPH_K_INITIAL, GRAPH_MAX_HOPS, GRAPH_MAX_ENTITIES, client, gemini_client\n",
        "        )\n",
        "\n",
        "        # Generate an answer for each context\n",
        "        print(f\"\\nGenerating answers for query: '{query[:50]}...'\")\n",
        "        answer_vanilla = generate_answer(query, vanilla_context, gemini_client)\n",
        "        answer_graph = generate_answer(query, graph_context, gemini_client)\n",
        "\n",
        "        # Have the judge decide which answer is better\n",
        "        vote = judge_answers(query, answer_vanilla, answer_graph, gemini_client)\n",
        "\n",
        "        # Tally the votes\n",
        "        if vote == 1:\n",
        "            scores[\"vanilla_wins\"] += 1\n",
        "            print(\">> Judge voted for: Vanilla RAG\")\n",
        "        elif vote == 2:\n",
        "            scores[\"graph_wins\"] += 1\n",
        "            print(\">> Judge voted for: Graph RAG\")\n",
        "        else:\n",
        "            scores[\"errors\"] += 1\n",
        "            print(\">> Failed to vote.\")\n",
        "\n",
        "    print(\"\\n--- LLM-as-a-Judge Evaluation Complete ---\")\n",
        "    return scores\n"
      ],
      "metadata": {
        "id": "hO3xQRSrSY5o"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper function to display theresults of the LLM-as-a-Judge evals."
      ],
      "metadata": {
        "id": "rIhL42Juh0E1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_judge_results(scores: dict):\n",
        "    \"\"\"Prints the final scorecard from the LLM-as-a-Judge evaluation.\"\"\"\n",
        "    total_queries = sum(scores.values())\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"           LLM-as-a-Judge Final Scorecard\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Total Queries Judged: {total_queries}\")\n",
        "    print(f\"Vanilla RAG Wins:     {scores['vanilla_wins']}\")\n",
        "    print(f\"Graph RAG Wins:       {scores['graph_wins']}\")\n",
        "    print(f\"Errors:       {scores['errors']}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    if scores['graph_wins'] > scores['vanilla_wins']:\n",
        "        print(\"\\nVerdict: Graph RAG produced higher-quality answers.\")\n",
        "    elif scores['vanilla_wins'] > scores['graph_wins']:\n",
        "        print(\"\\nVerdict: Vanilla RAG produced higher-quality answers.\")\n",
        "    else:\n",
        "        print(\"\\nVerdict: It's a tie!\")"
      ],
      "metadata": {
        "id": "t62hFlmcSwHx"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets run the evals and collect the scores."
      ],
      "metadata": {
        "id": "4mtqn982iElU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "judge_scores = run_llm_as_judge_evaluation(eval_queries, client, gemini_client)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3BEbrdjtW30K",
        "outputId": "ae1535b7-0a9a-490c-a9a6-4647955a1519"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting LLM-as-a-Judge Evaluation ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rJudging Queries:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating answers for query: 'How can AWS IAM policies be used to manage user ac...'\n",
            "The provided context states that 'Identity & Access Management (IAM)' (ID: 243) \"Manages user roles and authentication\" for AWS. It also describes 'Virtual Private Cloud (VPC)' (ID: 156, 170) as a logically isolated section within AWS. However, the context does not provide specific details on how AWS IAM policies are used to manage user access and permissions *within* a specific Virtual Private Cloud (VPC).\n",
            "I cannot answer based on the information given. The context states that 'Identity & Access Management (IAM)' manages user roles and authentication for AWS, and that 'Access Controls' and 'Network Policies' ensure isolation within a VPC, but it does not explain how AWS IAM policies specifically manage user access and permissions within a VPC.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rJudging Queries:  10%|█         | 1/10 [00:19<02:59, 19.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Judge voted for: Vanilla RAG\n",
            "\n",
            "Generating answers for query: 'Compare the specific functions of the L3 Agent and...'\n",
            "The L3 Agent connects cloud machines to the external world and provides routing, while the DHCP Agent assigns IP addresses dynamically. Both are components of an OpenStack Networking Node.\n",
            "Within an OpenStack Networking Node:\n",
            "*   The **L3 Agent** connects cloud machines to the external world and provides routing.\n",
            "*   The **DHCP Agent** dynamically assigns IP addresses.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rJudging Queries:  20%|██        | 2/10 [00:33<02:10, 16.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Judge voted for: Graph RAG\n",
            "\n",
            "Generating answers for query: 'Explain the full lifecycle: How do Cloud-Native Ap...'\n",
            "Cloud-Native Applications (CNA) are designed specifically for cloud environments and are built using a Microservices Architecture, meaning applications are split into small, independent services. These services are packaged into Containers, which are lightweight, provide an isolated environment, and share the host OS kernel. Containers are then deployed as Pods, which are the smallest deployable units in Kubernetes and can contain one or more containers.\n",
            "\n",
            "Kubernetes, as a container orchestration platform, manages and scales these containers across multiple machines. The Control Plane manages and schedules these containerized workloads across the Worker Nodes, which run the actual workloads. Key components like the Controller Manager maintain the state of Kubernetes objects, Kube-proxy manages network communication between pods, and etcd provides persistent storage for configuration data. Kubernetes also offers scalability features such as dynamically adding worker nodes as needed.\n",
            "Cloud-Native Applications (CNA) are designed specifically for cloud environments and are built using a Microservices Architecture. This means the application is split into small, independent services.\n",
            "\n",
            "These individual services are then packaged into \"Containers,\" which are lightweight, isolated environments that run specific applications, sharing the host OS kernel for efficiency and rapid creation/destruction.\n",
            "\n",
            "Finally, these containerized applications are deployed and managed by an orchestration platform like \"Kubernetes.\" Kubernetes manages, orchestrates, and scales containers across multiple machines (clusters). In Kubernetes, containers are deployed within \"Pods,\" which are the smallest deployable unit and can contain one or more containers. Kubernetes adds worker nodes dynamically as needed for scalability. Deployment can involve building custom Kubernetes clusters or using Kubernetes as a managed service (Kubernetes as a Service (Managed)), which offers cluster provisioning, elastic scaling, and auto-management. Logging is crucial for tracking container events within this environment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rJudging Queries:  30%|███       | 3/10 [00:55<02:12, 18.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Judge voted for: Vanilla RAG\n",
            "\n",
            "Generating answers for query: 'Why is para-virtualization, as used by the Xen hyp...'\n",
            "The context states that Full Virtualization has \"Higher overhead due to full emulation,\" and Para-Virtualization has \"Performance optimization due to lower overhead.\" However, the context does not provide the specific reason *why* para-virtualization has lower overhead compared to full virtualization.\n",
            "Para-virtualization has lower overhead because the hypervisor provides a specialized interface that does not exist in physical hardware. In contrast, full virtualization has higher overhead due to full emulation, as its hypervisor exposes the same hardware interface as physical hardware.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rJudging Queries:  40%|████      | 4/10 [01:11<01:45, 17.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Judge voted for: Graph RAG\n",
            "\n",
            "Generating answers for query: 'What is the primary use case for attaching an EBS ...'\n",
            "The primary use case for attaching an EBS volume, a type of block storage, to an AWS EC2 instance is for persistent storage on EC2 instances.\n",
            "The primary use case for attaching an EBS volume, a type of block storage, to an AWS EC2 instance is for persistent storage.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rJudging Queries:  50%|█████     | 5/10 [01:23<01:17, 15.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Judge voted for: Graph RAG\n",
            "\n",
            "Generating answers for query: 'Describe the process of a VM launch in OpenStack, ...'\n",
            "Based only on the provided context, the detailed process of a VM launch in OpenStack is not described. However, the roles of the specified services in the context of VM management are as follows:\n",
            "\n",
            "*   **Image Service**: Handles the creation and management of VM images, which would be used as the base for launching a VM.\n",
            "*   **Compute Service**: Manages the overall VM lifecycle, including making VM scheduling decisions and distributing resources across machines. It is the service responsible for launching and managing VMs, and it utilizes KVM as its default hypervisor.\n",
            "*   **KVM Hypervisor**: Runs virtual machines on a single physical machine by abstracting hardware resources. It is the default hypervisor used by OpenStack's Compute Service and is responsible for virtual machine execution, process isolation, resource management, and hardware access control on the Compute Nodes.\n",
            "\n",
            "The context defines the general functions of these services related to VM management but does not provide the step-by-step process or interactions involved in a VM launch.\n",
            "While the provided context describes the functions and relationships of the services, it does not explicitly detail the step-by-step sequence of a VM launch process. However, based on the given information, their roles in a VM launch can be described as follows:\n",
            "\n",
            "*   **Compute Service:** This service is responsible for managing the VM lifecycle, which includes initiating and overseeing the launch of a VM. It also distributes resources across machines and makes scheduling decisions, determining on which Compute Node the VM will be placed. The Compute Service uses KVM as its default hypervisor.\n",
            "*   **Image Service:** The Image Service handles the creation and management of VM images. Therefore, during a VM launch, the necessary virtual disk image for the new VM would be sourced from this service.\n",
            "*   **KVM Hypervisor:** Used by the Compute Service on a Compute Node, the KVM hypervisor is the underlying software layer that directly runs the VM. It allows multiple virtual machines to execute on a single physical machine by abstracting hardware resources. For a newly launched VM, KVM is responsible for its execution, providing process isolation, resource management, and hardware access control.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rJudging Queries:  60%|██████    | 6/10 [01:56<01:26, 21.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Judge voted for: Graph RAG\n",
            "\n",
            "Generating answers for query: 'Compare the security characteristics and control l...'\n",
            "Private Cloud offers more control and more security. For Public Cloud, security can be a concern; its control level is not explicitly detailed in the context for direct comparison.\n",
            "**Security Characteristics:**\n",
            "*   **Private Cloud:** Offers \"More security.\"\n",
            "*   **Public Cloud:** \"Security can be a concern.\"\n",
            "\n",
            "**Control Levels:**\n",
            "*   **Private Cloud:** Provides \"More control.\"\n",
            "*   The context does not specify the control level for Public Cloud.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rJudging Queries:  70%|███████   | 7/10 [02:16<01:03, 21.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Judge voted for: Graph RAG\n",
            "\n",
            "Generating answers for query: 'How does a Multicloud strategy help an organizatio...'\n",
            "A Multicloud strategy helps an organization avoid vendor lock-in by utilizing services from multiple cloud providers.\n",
            "\n",
            "Major cloud service providers mentioned in the context that are major players in this ecosystem include AWS (Amazon Web Services), Azure (Microsoft Azure), GCP (Google Cloud), and IBM Cloud.\n",
            "A Multicloud strategy helps an organization avoid vendor lock-in by utilizing services from multiple cloud providers. The context identifies GCP and IBM Cloud as major companies that hold a significant portion of cloud infrastructure.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rJudging Queries:  80%|████████  | 8/10 [02:30<00:37, 18.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Judge voted for: Vanilla RAG\n",
            "\n",
            "Generating answers for query: 'What role does middleware for 'Provisioning & Conf...'\n",
            "Middleware for 'Provisioning & Configuration' helps in cloud deployment and workload management, which enables the 'On-Demand Self-Service' characteristic by allowing users to configure and deploy services independently without human intervention.\n",
            "The provided context states that 'Provisioning & Configuration' middleware \"Helps in cloud deployment and workload management.\" It also states that 'On-Demand Self-Service' means \"Users can configure and deploy services independently, without requiring human intervention.\" However, the context does not explicitly explain the specific role 'Provisioning & Configuration' middleware plays in *enabling* the 'On-Demand Self-Service' characteristic beyond its general function of helping with cloud deployment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rJudging Queries:  90%|█████████ | 9/10 [02:45<00:17, 17.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Judge voted for: Vanilla RAG\n",
            "\n",
            "Generating answers for query: 'Explain how Open vSwitch enables software-defined ...'\n",
            "The context states that Open vSwitch \"Enables software-defined networking (SDN) in OpenStack\" and \"Allows unlimited VMs to connect\". It also notes that Open vSwitch is a component of both \"Compute Nodes\" and \"Network Nodes\". However, the provided context does not explain *how* Open vSwitch connects virtual machines on these nodes to enable SDN.\n",
            "Open vSwitch enables software-defined networking (SDN) in OpenStack as a software-based network switch. It is a component on both Compute Nodes and Network Nodes, and allows unlimited virtual machines (VMs) to connect. However, the provided context does not explain the specific mechanism of how Open vSwitch connects virtual machines *between* Compute and Network nodes to enable SDN.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Judging Queries: 100%|██████████| 10/10 [03:05<00:00, 18.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Judge voted for: Graph RAG\n",
            "\n",
            "--- LLM-as-a-Judge Evaluation Complete ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The moment of truth - lets display the results."
      ],
      "metadata": {
        "id": "sC4QKZ5_iiY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_judge_results(judge_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BsbNNcZ-YPJb",
        "outputId": "92e7eec9-438a-4024-ff0c-55d09e0e4eb6"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "           LLM-as-a-Judge Final Scorecard\n",
            "==================================================\n",
            "Total Queries Judged: 10\n",
            "Vanilla RAG Wins:     4\n",
            "Graph RAG Wins:       6\n",
            "Errors:       0\n",
            "==================================================\n",
            "\n",
            "Verdict: Graph RAG produced higher-quality answers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final scorecard shows that **Graph RAG is the winner.**\n",
        "\n",
        "This result demonstrates that while its retrieved context had less direct overlap with the golden set, the structure and rich connections within that context enabled the generator LLM to produce superior, more helpful answers. This confirms the value of Graph RAG in a way that the numerical metrics could not."
      ],
      "metadata": {
        "id": "7F2lmtZnipXN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "irzj9_fLiqpv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}